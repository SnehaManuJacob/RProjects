{
  "hash": "e02231e3e3925a968e89c6cc07363d8f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Day 4\"\nauthor: \"Sneha Manu Jacob\"\ndate: \"2024-10-04\"\ncategories: [quantities, histogram]\n---\n\n\n\n\n## Introduction:\n\nQuant and Qual Variable Graphs and their Siblings (god knows what that means).\n\nA **histogram** is a graphical representation of the distribution of continuous numerical data, where data is grouped into ranges (or bins), and the frequency of data points in each bin is displayed using bars. **Quant**Â variables will be present on theÂ x-axisÂ and the histogram shows us how frequently different values occur for that variable by showingÂ *counts/frequencies*Â on the y-axis. we use \"gf_histogram\" for this.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nâ”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€\nâœ” dplyr     1.1.4     âœ” readr     2.1.5\nâœ” forcats   1.0.0     âœ” stringr   1.5.1\nâœ” ggplot2   3.5.1     âœ” tibble    3.2.1\nâœ” lubridate 1.9.3     âœ” tidyr     1.3.1\nâœ” purrr     1.0.2     \nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– dplyr::filter() masks stats::filter()\nâœ– dplyr::lag()    masks stats::lag()\nâ„¹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(mosaic)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(ggformula)\nlibrary(skimr)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n```\n\n\n:::\n\n```{.r .cell-code}\n##\nlibrary(crosstable)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n```\n\n\n:::\n:::\n\n\n\n\n## Diamonds data-set:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiamonds\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 53,940 Ã— 10\n   carat cut       color clarity depth table price     x     y     z\n   <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n 7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n 8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n 9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n# â„¹ 53,930 more rows\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(diamonds)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 53,940\nColumns: 10\n$ carat   <dbl> 0.23, 0.21, 0.23, 0.29, 0.31, 0.24, 0.24, 0.26, 0.22, 0.23, 0.â€¦\n$ cut     <ord> Ideal, Premium, Good, Premium, Good, Very Good, Very Good, Verâ€¦\n$ color   <ord> E, E, E, I, J, J, I, H, E, H, J, J, F, J, E, E, I, J, J, J, I,â€¦\n$ clarity <ord> SI2, SI1, VS1, VS2, SI2, VVS2, VVS1, SI1, VS2, VS1, SI1, VS1, â€¦\n$ depth   <dbl> 61.5, 59.8, 56.9, 62.4, 63.3, 62.8, 62.3, 61.9, 65.1, 59.4, 64â€¦\n$ table   <dbl> 55, 61, 65, 58, 58, 57, 57, 55, 61, 61, 55, 56, 61, 54, 62, 58â€¦\n$ price   <int> 326, 326, 327, 334, 335, 336, 336, 337, 337, 338, 339, 340, 34â€¦\n$ x       <dbl> 3.95, 3.89, 4.05, 4.20, 4.34, 3.94, 3.95, 4.07, 3.87, 4.00, 4.â€¦\n$ y       <dbl> 3.98, 3.84, 4.07, 4.23, 4.35, 3.96, 3.98, 4.11, 3.78, 4.05, 4.â€¦\n$ z       <dbl> 2.43, 2.31, 2.31, 2.63, 2.75, 2.48, 2.47, 2.53, 2.49, 2.39, 2.â€¦\n```\n\n\n:::\n:::\n\n\n\n\n> Considering the fact that all qualitative data is already ordered and factored, we don't mutate any values here.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nskim(diamonds)\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |         |\n|:------------------------|:--------|\n|Name                     |diamonds |\n|Number of rows           |53940    |\n|Number of columns        |10       |\n|_______________________  |         |\n|Column type frequency:   |         |\n|factor                   |3        |\n|numeric                  |7        |\n|________________________ |         |\n|Group variables          |None     |\n\n\n**Variable type: factor**\n\n|skim_variable | n_missing| complete_rate|ordered | n_unique|top_counts                                    |\n|:-------------|---------:|-------------:|:-------|--------:|:---------------------------------------------|\n|cut           |         0|             1|TRUE    |        5|Ide: 21551, Pre: 13791, Ver: 12082, Goo: 4906 |\n|color         |         0|             1|TRUE    |        7|G: 11292, E: 9797, F: 9542, H: 8304           |\n|clarity       |         0|             1|TRUE    |        8|SI1: 13065, VS2: 12258, SI2: 9194, VS1: 8171  |\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|    mean|      sd|    p0|    p25|     p50|     p75|     p100|hist  |\n|:-------------|---------:|-------------:|-------:|-------:|-----:|------:|-------:|-------:|--------:|:-----|\n|carat         |         0|             1|    0.80|    0.47|   0.2|   0.40|    0.70|    1.04|     5.01|â–‡â–‚â–â–â– |\n|depth         |         0|             1|   61.75|    1.43|  43.0|  61.00|   61.80|   62.50|    79.00|â–â–â–‡â–â– |\n|table         |         0|             1|   57.46|    2.23|  43.0|  56.00|   57.00|   59.00|    95.00|â–â–‡â–â–â– |\n|price         |         0|             1| 3932.80| 3989.44| 326.0| 950.00| 2401.00| 5324.25| 18823.00|â–‡â–‚â–â–â– |\n|x             |         0|             1|    5.73|    1.12|   0.0|   4.71|    5.70|    6.54|    10.74|â–â–â–‡â–ƒâ– |\n|y             |         0|             1|    5.73|    1.14|   0.0|   4.72|    5.71|    6.54|    58.90|â–‡â–â–â–â– |\n|z             |         0|             1|    3.54|    0.71|   0.0|   2.91|    3.53|    4.04|    31.80|â–‡â–â–â–â– |\n\n\n:::\n:::\n\n\n\n\n> -   `carat`: weight of the diamond 0.2-5.01\n>\n> -   `depth`: depth total depth percentage 43-79\n>\n> -   `table`: width of top of diamond relative to widest point 43-95\n>\n> -   `price`: price in US dollars \\$326-\\$18,823\n>\n> -   `x`: length in mm 0-10.74\n>\n> -   `y`: width in mm 0-58.9\n>\n> -   `z`(dbl): depth in mm 0-31.8\n>\n> <!-- -->\n>\n> -   There are no missing values for any variable, all are complete with 54K entries.\n\nMy first histogram!!!!\n\n### Plotting diamond prices.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## if i want i can not specigy the bins too. \ngf_histogram(~price,\n  data = diamonds,\n  bins = 100\n) %>%\n  gf_labs(\n    title = \"Plot 1A: Diamond Prices\",\n    caption = \"ggformula\"\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n\nWe can infer that while a large number of diamonds are priced relatively low, there are also a significant number of diamonds that are priced very high.\n\n### **What is the distribution of the predictor variable carat?**\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiamonds %>%\n  gf_histogram(~carat,\n    bins = 100\n  ) %>%\n  gf_labs(\n    title = \"Plot 2B: Carats of Diamonds\",\n    caption = \"ggformula\"\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n\nWe can infer that there must be some, very few, diamonds of very high carat value while there a few carat values that appear to be more than common! People very commonly buy diamonds of 1 carat and a little less frequently 0.5, 1.5 and 2.\n\n### **Does a price distribution vary based upon type of** cut?\n\n> from what i observe, the fill acts as a stack here, although it is prices that are represented in the historgram, we able to observe what portion of each bin is occupied by each of the cuts\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_histogram(~price, fill = ~cut, data = diamonds, bins=100) %>%\n  gf_labs(title = \"Plot 3A: Diamond Prices\", caption = \"ggformula\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndiamonds %>%\n  gf_histogram(~price|cut, fill = ~cut, color = \"black\", alpha = 0.3) %>%\n  gf_labs(\n    title = \"Plot 3C: Prices by Filled and Facetted by Cut\",\n    caption = \"ggformula\"\n  ) %>%\n  gf_theme(theme(\n    axis.text.x = element_text(\n      angle = 45, ## the angle at which the word should be placed.\n      hjust = 1 ## the incremanting space from the x axis\n    )\n  ))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n\nusing this, we can observe the price range of each individual cut as different graphs, but very low values (in comparison to high values of ideal) such as those in fair and good. We can make them have ranges of values in y axis based on their individual values by setting scales to be free y.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## the nrow, defines the number of rows \ndiamonds %>%\n  gf_histogram(~price, fill = ~cut, color = \"black\", alpha = 0.3) %>%\n  gf_facet_wrap(~cut, scales = \"free_y\", nrow = 2) %>%\n  gf_labs(\n    title = \"Plot 3D: Prices Filled and Facetted by Cut\",\n    subtitle = \"Free y-scale\",\n    caption = \"ggformula\"\n  ) %>%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n\nPrice ranges are the same regardless of cut and so that must not be the only parameter in dermeining the price\n\n### **Does a price distribution vary based upon type of** clarity?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_histogram(~price, fill = ~clarity, data = diamonds) %>%\n  gf_labs(title = \"Plot 3A: Diamond Prices spereated by clarity\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndiamonds %>%\n  gf_histogram(~price, fill = ~clarity, color = \"black\", alpha = 0.3) %>%\n  gf_facet_wrap(~clarity) %>%\n  gf_labs(\n    title = \"Plot 4A: Prices Filled and Facetted by Clarity\",\n    subtitle = \"Free y-scale\",\n    caption = \"ggformula\"\n  ) %>%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n## the nrow, defines the number of rows \ndiamonds %>%\n  gf_histogram(~price, fill = ~clarity, color = \"black\", alpha = 0.3) %>%\n  gf_facet_wrap(~clarity, scales = \"free_y\", nrow = 2) %>%\n  gf_labs(\n    title = \"Plot 4A: Prices Filled and Facetted by Clarity\",\n    subtitle = \"Free y-scale\",\n    caption = \"ggformula\"\n  ) %>%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n\n\nPrice ranges are the same regardless of clarity and so that must not be the only parameter in determining the price but SI1 appease to have the most in high prices\n\n### **Does a price distribution vary based upon type of** colour?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_histogram(~price, fill = ~color, data = diamonds) %>%\n  gf_labs(title = \"Plot: Diamond Prices spereated by color\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndiamonds %>%\n  gf_histogram(~price, fill = ~color, color = \"black\", alpha = 0.3) %>%\n  gf_facet_wrap(~color) %>%\n  gf_labs(\n    title = \"Plot: Prices Filled and Facetted by Color\",\n    subtitle = \"Free y-scale\",\n  ) %>%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndiamonds %>%\n  gf_histogram(~price, fill = ~color, color = \"black\", alpha = 0.3) %>%\n  gf_facet_wrap(~color, scales = \"free_y\", nrow = 2) %>%\n  gf_labs(\n    title = \"Plot: Prices Filled and Facetted by Color\",\n    subtitle = \"Free y-scale\",\n  ) %>%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n\n\n## The Race data-set\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrace_df <- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-26/race.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 1207 Columns: 13\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr  (5): event, race, city, country, participation\ndbl  (6): race_year_id, distance, elevation_gain, elevation_loss, aid_statio...\ndate (1): date\ntime (1): start_time\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nrace_df\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,207 Ã— 13\n   race_year_id event    race  city  country date       start_time participation\n          <dbl> <chr>    <chr> <chr> <chr>   <date>     <time>     <chr>        \n 1        68140 Peak Diâ€¦ Millâ€¦ Castâ€¦ Unitedâ€¦ 2021-09-03 19:00      solo         \n 2        72496 UTMBÂ®    UTMBÂ® Chamâ€¦ France  2021-08-27 17:00      Solo         \n 3        69855 Grand Râ€¦ Ultrâ€¦ vielâ€¦ France  2021-08-20 05:00      solo         \n 4        67856 Persenkâ€¦ PERSâ€¦ Asenâ€¦ Bulgarâ€¦ 2021-08-20 18:00      solo         \n 5        70469 Runfireâ€¦ 100 â€¦ ulukâ€¦ Turkey  2021-08-20 18:00      solo         \n 6        66887 Swiss Aâ€¦ 160KM MÃ¼nsâ€¦ Switzeâ€¦ 2021-08-15 17:00      solo         \n 7        67851 Salomonâ€¦ Saloâ€¦ Follâ€¦ Norway  2021-08-14 07:00      solo         \n 8        68241 Ultra Tâ€¦ 160KM Spa   Belgium 2021-08-14 07:00      solo         \n 9        70241 QuÃ©bec â€¦ QMT-â€¦ Beauâ€¦ Canada  2021-08-13 22:00      solo         \n10        69945 Bunketoâ€¦ BBUTâ€¦ LINDâ€¦ Sweden  2021-08-07 10:00      solo         \n# â„¹ 1,197 more rows\n# â„¹ 5 more variables: distance <dbl>, elevation_gain <dbl>,\n#   elevation_loss <dbl>, aid_stations <dbl>, participants <dbl>\n```\n\n\n:::\n\n```{.r .cell-code}\nrank_df <- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-26/ultra_rankings.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 137803 Columns: 8\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr (4): runner, time, gender, nationality\ndbl (4): race_year_id, rank, age, time_in_seconds\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nrank_df\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 137,803 Ã— 8\n   race_year_id  rank runner      time    age gender nationality time_in_seconds\n          <dbl> <dbl> <chr>       <chr> <dbl> <chr>  <chr>                 <dbl>\n 1        68140     1 VERHEUL Jaâ€¦ 26H â€¦    30 M      GBR                   95725\n 2        68140     2 MOULDING Jâ€¦ 27H â€¦    43 M      GBR                   97229\n 3        68140     3 RICHARDSONâ€¦ 28H â€¦    38 M      GBR                  103747\n 4        68140     4 DYSON Fiona 30H â€¦    55 W      GBR                  111217\n 5        68140     5 FRONTERAS â€¦ 32H â€¦    48 W      GBR                  117981\n 6        68140     6 THOMAS Leiâ€¦ 32H â€¦    31 M      GBR                  118000\n 7        68140     7 SHORT Deboâ€¦ 33H â€¦    55 W      GBR                  120601\n 8        68140     8 CROSSLEY Câ€¦ 33H â€¦    40 W      GBR                  120803\n 9        68140     9 BUTCHER Keâ€¦ 34H â€¦    47 M      GBR                  125656\n10        68140    10 Hendry Bill 34H â€¦    29 M      GBR                  125979\n# â„¹ 137,793 more rows\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(race_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 1,207\nColumns: 13\n$ race_year_id   <dbl> 68140, 72496, 69855, 67856, 70469, 66887, 67851, 68241,â€¦\n$ event          <chr> \"Peak District Ultras\", \"UTMBÂ®\", \"Grand Raid des PyrÃ©nÃ©â€¦\n$ race           <chr> \"Millstone 100\", \"UTMBÂ®\", \"Ultra Tour 160\", \"PERSENK ULâ€¦\n$ city           <chr> \"Castleton\", \"Chamonix\", \"vielle-Aure\", \"Asenovgrad\", \"â€¦\n$ country        <chr> \"United Kingdom\", \"France\", \"France\", \"Bulgaria\", \"Turkâ€¦\n$ date           <date> 2021-09-03, 2021-08-27, 2021-08-20, 2021-08-20, 2021-0â€¦\n$ start_time     <time> 19:00:00, 17:00:00, 05:00:00, 18:00:00, 18:00:00, 17:0â€¦\n$ participation  <chr> \"solo\", \"Solo\", \"solo\", \"solo\", \"solo\", \"solo\", \"solo\",â€¦\n$ distance       <dbl> 166.9, 170.7, 167.0, 164.0, 159.9, 159.9, 163.8, 163.9,â€¦\n$ elevation_gain <dbl> 4520, 9930, 9980, 7490, 100, 9850, 5460, 4630, 6410, 31â€¦\n$ elevation_loss <dbl> -4520, -9930, -9980, -7500, -100, -9850, -5460, -4660, â€¦\n$ aid_stations   <dbl> 10, 11, 13, 13, 12, 15, 5, 8, 13, 23, 13, 5, 12, 15, 0,â€¦\n$ participants   <dbl> 150, 2300, 600, 150, 0, 300, 0, 200, 120, 100, 300, 50,â€¦\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(rank_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 137,803\nColumns: 8\n$ race_year_id    <dbl> 68140, 68140, 68140, 68140, 68140, 68140, 68140, 68140â€¦\n$ rank            <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, NA, NA, NA,â€¦\n$ runner          <chr> \"VERHEUL Jasper\", \"MOULDING JON\", \"RICHARDSON Phill\", â€¦\n$ time            <chr> \"26H 35M 25S\", \"27H 0M 29S\", \"28H 49M 7S\", \"30H 53M 37â€¦\n$ age             <dbl> 30, 43, 38, 55, 48, 31, 55, 40, 47, 29, 48, 47, 52, 49â€¦\n$ gender          <chr> \"M\", \"M\", \"M\", \"W\", \"W\", \"M\", \"W\", \"W\", \"M\", \"M\", \"M\",â€¦\n$ nationality     <chr> \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\"â€¦\n$ time_in_seconds <dbl> 95725, 97229, 103747, 111217, 117981, 118000, 120601, â€¦\n```\n\n\n:::\n:::\n\n\n\n\n> mosaic::favstats returns a data frame with several common summary statistics, such as:\n>\n> -   **min**: Minimum value\n>\n> -   **Q1**: First quartile (25th percentile)\n>\n> -   **median**: Median (50th percentile)\n>\n> -   **Q3**: Third quartile (75th percentile)\n>\n> -   **max**: Maximum value\n>\n> -   **mean**: Arithmetic mean\n>\n> -   **sd**: Standard deviation\n>\n> -   **n**: Number of non-missing observations\n>\n> -   **missing**: Number of missing values\n>\n> -   **IQR**: Interquartile range (Q3 - Q1)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrace_df %>%\n  favstats(~distance, data = .)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n min    Q1 median     Q3   max     mean       sd    n missing\n   0 160.1  161.5 165.15 179.1 152.6187 39.87864 1207       0\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrace_df %>%\n  favstats(~participants, data = .)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n min Q1 median  Q3  max     mean       sd    n missing\n   0  0     21 150 2900 120.4872 281.8337 1207       0\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrank_df %>%\n  drop_na() %>%\n  favstats(time_in_seconds ~ gender, data = .)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  gender  min      Q1 median       Q3    max     mean       sd      n missing\n1      M 3600 96536.5 115845 149761.5 288000 123271.1 37615.42 101643       0\n2      W 9191 96695.0 107062 131464.0 296806 117296.5 34604.26  18341       0\n```\n\n\n:::\n:::\n\n\n\n\n> On occasion we may need to see summaries of several Quant variables, over levels of Qual variables. This is where the packageÂ crosstableÂ is so effective. Therefore, crosstable is useful when you need to generate summary statistics of **quantitative (numeric)** variables, broken down by levels of **qualitative (categorical)** variables.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncrosstable(time_in_seconds + age ~ gender, data = rank_df) %>%\n  crosstable::as_flextable()\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"tabwid\"><style>.cl-5f37505e{table-layout:auto;}.cl-5f267b30{font-family:'Arial';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-5f267b44{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-5f2dfe14{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-5f2dfe32{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-5f2e2592{background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(0, 0, 0, 1.00);border-top: 1.5pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5f2e259c{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1.5pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5f2e25a6{background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5f2e25b0{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5f2e25b1{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5f2e25ba{background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5f2e25bb{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5f2e25bc{background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-5f37505e'><thead><tr style=\"overflow-wrap:break-word;\"><th  rowspan=\"2\"class=\"cl-5f2e2592\"><p class=\"cl-5f2dfe14\"><span class=\"cl-5f267b30\">label</span></p></th><th  rowspan=\"2\"class=\"cl-5f2e2592\"><p class=\"cl-5f2dfe14\"><span class=\"cl-5f267b30\">variable</span></p></th><th  colspan=\"3\"class=\"cl-5f2e259c\"><p class=\"cl-5f2dfe14\"><span class=\"cl-5f267b30\">gender</span></p></th></tr><tr style=\"overflow-wrap:break-word;\"><th class=\"cl-5f2e25a6\"><p class=\"cl-5f2dfe14\"><span class=\"cl-5f267b30\">M</span></p></th><th class=\"cl-5f2e25a6\"><p class=\"cl-5f2dfe14\"><span class=\"cl-5f267b30\">W</span></p></th><th class=\"cl-5f2e25a6\"><p class=\"cl-5f2dfe14\"><span class=\"cl-5f267b30\">NA</span></p></th></tr></thead><tbody><tr style=\"overflow-wrap:break-word;\"><td  rowspan=\"4\"class=\"cl-5f2e25b0\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">time_in_seconds</span></p></td><td class=\"cl-5f2e25b1\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">Min / Max</span></p></td><td class=\"cl-5f2e25b1\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">3600.0 / 2.9e+05</span></p></td><td class=\"cl-5f2e25b1\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">9191.0 / 3.0e+05</span></p></td><td class=\"cl-5f2e25b1\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">8131.0 / 2.2e+05</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-5f2e25b1\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">Med [IQR]</span></p></td><td class=\"cl-5f2e25b1\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">1.2e+05 [9.7e+04;1.5e+05]</span></p></td><td class=\"cl-5f2e25b1\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">1.1e+05 [9.7e+04;1.3e+05]</span></p></td><td class=\"cl-5f2e25b1\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">1.2e+05 [9.9e+04;1.5e+05]</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-5f2e25b1\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">Mean (std)</span></p></td><td class=\"cl-5f2e25b1\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">1.2e+05 (3.8e+04)</span></p></td><td class=\"cl-5f2e25b1\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">1.2e+05 (3.5e+04)</span></p></td><td class=\"cl-5f2e25b1\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">1.2e+05 (4.4e+04)</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-5f2e25b0\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">N (NA)</span></p></td><td class=\"cl-5f2e25b0\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">101643 (15073)</span></p></td><td class=\"cl-5f2e25b0\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">18341 (2716)</span></p></td><td class=\"cl-5f2e25b0\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">28 (2)</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td  rowspan=\"4\"class=\"cl-5f2e25ba\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">age</span></p></td><td class=\"cl-5f2e25bb\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">Min / Max</span></p></td><td class=\"cl-5f2e25bb\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">0 / 133.0</span></p></td><td class=\"cl-5f2e25bb\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">0 / 81.0</span></p></td><td class=\"cl-5f2e25bb\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">29.0 / 59.0</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-5f2e25b1\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">Med [IQR]</span></p></td><td class=\"cl-5f2e25b1\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">47.0 [40.0;53.0]</span></p></td><td class=\"cl-5f2e25b1\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">45.0 [39.0;52.0]</span></p></td><td class=\"cl-5f2e25b1\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">40.5 [36.0;50.5]</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-5f2e25b1\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">Mean (std)</span></p></td><td class=\"cl-5f2e25b1\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">46.4 (10.2)</span></p></td><td class=\"cl-5f2e25b1\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">45.3 (9.7)</span></p></td><td class=\"cl-5f2e25b1\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">41.7 (9.0)</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-5f2e25bc\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">N (NA)</span></p></td><td class=\"cl-5f2e25bc\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">116716 (0)</span></p></td><td class=\"cl-5f2e25bc\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">21057 (0)</span></p></td><td class=\"cl-5f2e25bc\"><p class=\"cl-5f2dfe32\"><span class=\"cl-5f267b44\">30 (0)</span></p></td></tr></tbody></table></div>\n```\n\n:::\n:::\n\n\n\n\nMen participating are generally older than women. When it comes to time in seconds, while the overall central tendency (mean) remains consistent, the distribution of the data has some variation as shown by (std) and (median) but not the average - it's the same.\n\n### Which countries host the maximum number of races? Which countries send the maximum number of participants??\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrace_df %>%\n  count(country) %>%\n  arrange(desc(n))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 61 Ã— 2\n   country            n\n   <chr>          <int>\n 1 United States    438\n 2 United Kingdom   110\n 3 France            56\n 4 Australia         46\n 5 Sweden            46\n 6 China             45\n 7 Canada            32\n 8 Spain             27\n 9 Japan             24\n10 Poland            23\n# â„¹ 51 more rows\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrank_df %>%\n  count(nationality) %>%\n  arrange(desc(n))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 133 Ã— 2\n   nationality     n\n   <chr>       <int>\n 1 USA         47259\n 2 FRA         28905\n 3 GBR         11076\n 4 JPN          6729\n 5 ESP          5478\n 6 CHN          4744\n 7 CAN          2822\n 8 ITA          2794\n 9 SWE          2293\n10 AUS          1683\n# â„¹ 123 more rows\n```\n\n\n:::\n:::\n\n\n\n\nThe United states hosts the most number of games and send the most number of players.\n\n### Which country wins the most?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrank_df %>%\n  filter(rank %in% c(1, 2, 3)) %>%\n  count(nationality) %>%\n  arrange(desc(n))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 69 Ã— 2\n   nationality     n\n   <chr>       <int>\n 1 USA          1240\n 2 GBR           347\n 3 FRA           210\n 4 AUS           140\n 5 CAN           132\n 6 CHN           128\n 7 SWE           124\n 8 ESP           113\n 9 JPN            94\n10 ITA            79\n# â„¹ 59 more rows\n```\n\n\n:::\n:::\n\n\n\n\nTo no surprise, United states wins the most too. Would it be the same case if compared the ratio of players to wins?\n\n### Analyze the nationality of the top 10 participants in the longest races\n\n> -   slice() allows you to select, remove, and duplicate rows. slice_min() and `slice_max()` select rows with the smallest or largest values of a variable.\n> -   TheÂ `filter()`Â function is used to subset a data frame, retaining all rows that satisfy your conditions.\n> -   **`left_join()`** is a function from the **`dplyr`** package used to combine two data frames by joining them based on a common column (or columns).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlongest_races <- race_df %>%\n  slice_max(n = 5, order_by = distance) # Longest distance races\nlongest_races\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 Ã— 13\n  race_year_id event     race  city  country date       start_time participation\n         <dbl> <chr>     <chr> <chr> <chr>   <date>     <time>     <chr>        \n1        68776 Ultra Toâ€¦ Ut4Mâ€¦ Grenâ€¦ France  2021-07-16 18:00      Solo         \n2        55551 Ultra Trâ€¦ Inthâ€¦ Chomâ€¦ Thailaâ€¦ 2020-02-14 10:00      solo         \n3         7484 Le TREGÂ®â€¦ LE Tâ€¦ Fada  Chad    2015-02-06 00:00      solo         \n4         7594 THE GREAâ€¦ 100 â€¦ Patoâ€¦ Austraâ€¦ 2014-09-13 00:00      Solo         \n5        71066 ULTRA 01  Ultrâ€¦ Oyonâ€¦ France  2021-07-09 18:00      solo         \n6        23565 EstrelAÃ§â€¦ Estrâ€¦ Penhâ€¦ Portugâ€¦ 2017-10-06 18:00      Solo         \n# â„¹ 5 more variables: distance <dbl>, elevation_gain <dbl>,\n#   elevation_loss <dbl>, aid_stations <dbl>, participants <dbl>\n```\n\n\n:::\n\n```{.r .cell-code}\nlongest_races %>%\n  left_join(., rank_df, by = \"race_year_id\") %>% # total participants in longest 4 races\n  filter(rank %in% c(1:10)) %>% # Top 10 ranks\n  count(nationality) %>%\n  arrange(desc(n))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 9 Ã— 2\n  nationality     n\n  <chr>       <int>\n1 FRA            26\n2 AUS             9\n3 POR             8\n4 THA             8\n5 BEL             1\n6 BRA             1\n7 ESP             1\n8 MAS             1\n9 RUS             1\n```\n\n\n:::\n:::\n\n\n\n\n> We get 2 tables - one with the joined data set, the other with the nationality and count of the amount of wins (top 10 rank among the longest races).\n\nThese quantities show that even though USA has the most number of wins, for the longest races, france has the most participents among everyone the top 10 rank.\n\n### **What is the distribution of the finishing times?**\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrank_df %>%\n  gf_histogram(~time_in_seconds, bins = 75) %>%\n  gf_labs(title = \"Histogram of Race Times\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 17791 rows containing non-finite outside the scale range\n(`stat_bin()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\n\n\nMost people finished the race at 1e+05. The histogram shows three bumps (is this a result of the difference in distance?)\n\n### **What is the distribution of race distances?**\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrace_df %>%\n  gf_histogram(~distance, bins = 50) %>%\n  gf_labs(title = \"Histogram of Race Distances\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n\n\n\nHow are there multiple races at 0 distance, is this a glitch in the data? There are very few races between 0-150. Most races seem to be set at a distance from 150 -180.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrace_df %>%\n  filter(distance == 0)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 74 Ã— 13\n   race_year_id event    race  city  country date       start_time participation\n          <dbl> <chr>    <chr> <chr> <chr>   <date>     <time>     <chr>        \n 1        64771 The Oldâ€¦ 100mâ€¦ Hanmâ€¦ New Zeâ€¦ 2021-05-14 10:00      solo         \n 2        71220 Run Lovâ€¦ 100M  <NA>  Unitedâ€¦ 2021-02-26 00:00      solo         \n 3        67160 IDAHO Mâ€¦ 100 â€¦ <NA>  Unitedâ€¦ 2020-09-12 00:00      solo         \n 4        67713 Pine crâ€¦ 100Mâ€¦ Wellâ€¦ PA, Unâ€¦ 2020-09-12 00:00      solo         \n 5        51777 Chiemgaâ€¦ 100 â€¦ Bergâ€¦ Germany 2020-07-31 13:00      Solo         \n 6        66413 Palisadâ€¦ Moosâ€¦ Irwin Unitedâ€¦ 2020-07-17 05:00      solo         \n 7        62593 Run Lovâ€¦ 100M  <NA>  Unitedâ€¦ 2020-02-28 00:00      solo         \n 8        50097 The Greâ€¦ The â€¦ Hanmâ€¦ New Zeâ€¦ 2020-01-17 07:00      solo         \n 9        65861 Loup Gaâ€¦ 100M  Villâ€¦ LA, Unâ€¦ 2019-12-14 00:00      solo         \n10        59415 RIO DELâ€¦ 100 â€¦ <NA>  Unitedâ€¦ 2019-11-07 00:00      solo         \n# â„¹ 64 more rows\n# â„¹ 5 more variables: distance <dbl>, elevation_gain <dbl>,\n#   elevation_loss <dbl>, aid_stations <dbl>, participants <dbl>\n```\n\n\n:::\n:::\n\n\n\n\nEven though there are so many races registerd as 100 mile races, non of the distances are 100 in the histogram.\n\n### **What is the distribution of finishing times for race distance around 150 faceted by time of day?**\n\nA count of start times:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrace_times <- race_df %>%\n  count(start_time) %>%\n  arrange(desc(n))\nrace_times\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 39 Ã— 2\n   start_time     n\n   <time>     <int>\n 1 00:00        513\n 2 06:00        114\n 3 08:00         63\n 4 10:00         60\n 5 07:00         58\n 6 18:00         50\n 7 05:00         48\n 8 12:00         38\n 9 04:00         30\n10 09:00         27\n# â„¹ 29 more rows\n```\n\n\n:::\n:::\n\n\n\n\nWe section a day into different groups of time: example morning, noon, evening and create a new column start_day_time with this information; since might and post midnight can be categorized as the same, we use fact_collapse to combine it to be the same. **`left_join()`** is used to merge `race_start_factor` with another data frame `rank_df` based on the `race_year_id` column, which is common between both. drop_na() removes any rows where `time_in_seconds` is `NA` (i.e., missing values). This ensures the plot only uses races with valid time data. hms- hour minute second.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrace_start_factor <- race_df %>%\n  filter(distance == 0) %>% # Races that actually took place\n  mutate(\n    ## start day time is a new column you are creating based on the values in\n    start_day_time =\n      case_when(\n        start_time > hms(\"02:00:00\") &\n          start_time <= hms(\"06:00:00\") ~ \"early_morning\",\n        start_time > hms(\"06:00:01\") &\n          start_time <= hms(\"10:00:00\") ~ \"late_morning\",\n        start_time > hms(\"10:00:01\") &\n          start_time <= hms(\"14:00:00\") ~ \"mid_day\",\n        start_time > hms(\"14:00:01\") &\n          start_time <= hms(\"18:00:00\") ~ \"afternoon\",\n        start_time > hms(\"18:00:01\") &\n          start_time <= hms(\"22:00:00\") ~ \"evening\",\n        start_time > hms(\"22:00:01\") &\n          start_time <= hms(\"23:59:59\") ~ \"night\",\n        start_time >= hms(\"00:00:00\") &\n          start_time <= hms(\"02:00:00\") ~ \"postmidnight\",\n        .default = \"other\"\n      )\n  ) %>%\n  mutate(\n    start_day_time =\n      as_factor(start_day_time) %>%\n        fct_collapse(\n          .f = .,\n          night = c(\"night\", \"postmidnight\")\n        )\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: There was 1 warning in `mutate()`.\nâ„¹ In argument: `start_day_time = `%>%`(...)`.\nCaused by warning:\n! Unknown levels in `f`: night\n```\n\n\n:::\n\n```{.r .cell-code}\n##\n# Join with rank_df\nrace_start_factor %>%\n  left_join(rank_df, by = \"race_year_id\") %>%\n  drop_na(time_in_seconds) %>%\n  gf_histogram(\n    ~time_in_seconds,\n    bins = 75,\n    fill = ~start_day_time,\n    color = ~start_day_time,\n    alpha = 0.5\n  ) %>%\n  gf_facet_wrap(vars(start_day_time), ncol = 2, scales = \"free_y\") %>%\n  gf_labs(title = \"Race Times by Start-Time\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n\n\n\nWe see that finish times tend to be longer for afternoon and evening start races\n\n## Populations data-set\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npop <- read_delim(\"../../data/populations.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 16400 Columns: 4\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr (2): country_code, country_name\ndbl (2): year, value\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\npop\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 16,400 Ã— 4\n   country_code country_name  year value\n   <chr>        <chr>        <dbl> <dbl>\n 1 ABW          Aruba         1960 54608\n 2 ABW          Aruba         1961 55811\n 3 ABW          Aruba         1962 56682\n 4 ABW          Aruba         1963 57475\n 5 ABW          Aruba         1964 58178\n 6 ABW          Aruba         1965 58782\n 7 ABW          Aruba         1966 59291\n 8 ABW          Aruba         1967 59522\n 9 ABW          Aruba         1968 59471\n10 ABW          Aruba         1969 59330\n# â„¹ 16,390 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\ninspect(pop)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\ncategorical variables:  \n          name     class levels     n missing\n1 country_code character    265 16400       0\n2 country_name character    265 16400       0\n                                   distribution\n1 ABW (0.4%), AFE (0.4%), AFG (0.4%) ...       \n2 Afghanistan (0.4%) ...                       \n\nquantitative variables:  \n   name   class  min       Q1  median       Q3        max         mean\n1  year numeric 1960   1975.0    1991     2006       2021 1.990529e+03\n2 value numeric 2646 986302.5 6731400 46024452 7888408686 2.140804e+08\n            sd     n missing\n1 1.789551e+01 16400       0\n2 7.040554e+08 16400       0\n```\n\n\n:::\n:::\n\n\n\n\nThere are many countries with small populations and a few countries with very large populations. Such distributions are also calledÂ **â€œlong tailedâ€**Â distributions.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_histogram(~value, data = pop, title = \"Long Tailed Histogram\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n\n```{.r .cell-code}\n##\ngf_density(~value, data = pop, title = \"Long Tailed Density\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-33-2.png){width=672}\n:::\n:::\n\n\n\n\nTo develop better insights with this data, we should transform the variable concerned, using say a â€œlogâ€ transformation:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_histogram(~ log10(value), data = pop, title = \"Histogram with Log transformed x-variable\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n\n```{.r .cell-code}\n##\ngf_density(~ log10(value), data = pop, title = \"Density with Log transformed x-variable\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-34-2.png){width=672}\n:::\n:::\n\n\n\n\n## What does each distribution signify?\n\n![](images/clipboard-3215234528.png)\n\n> -   *Bimodal*: There could be two different underlying processes or populations contributing to the data.\n>\n> -   *Comb*: The data might have been processed in a way that grouped values together in regular intervals.A comb distribution could appear in data where ages are rounded to the nearest five years (e.g., 20, 25, 30).\n>\n> -   *Edge Peak*: Could even be a data entry artifact!! All unknown / unrecorded observations are recorded as 999 !!ðŸ™€\n>\n> -   *Normal*: The data follows a typical pattern where most values are close to the mean, and extremes are rare.\nThis distribution occurs frequently in nature and in many datasets due to the Central Limit Theorem.\n>\n> -   *Skewed*: Right skew suggests that most values are clustered at the lower end, but there are some extreme high values.\nLeft skew suggests that most values are clustered at the higher end, but there are some extreme low values.\n>\n> -   *Uniform*: This can suggest random or non-preferential selection of values.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/tabwid-1.1.3/tabwid.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/tabwid-1.1.3/tabwid.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}