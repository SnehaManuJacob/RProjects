[
  {
    "objectID": "posts/My-name-is-Immortal/Index.html",
    "href": "posts/My-name-is-Immortal/Index.html",
    "title": "Day 1",
    "section": "",
    "text": "I’m a designer in training and like most people in the creatives, my interests cover a broad spectrum ranging from 3D Modelling and Lettering to Website Designs. I’m now working to add data visualisation and into my skill set, I hope I don’t totally suck at it!"
  },
  {
    "objectID": "posts/My-name-is-Immortal/Index.html#introduction",
    "href": "posts/My-name-is-Immortal/Index.html#introduction",
    "title": "Day 1",
    "section": "",
    "text": "I’m a designer in training and like most people in the creatives, my interests cover a broad spectrum ranging from 3D Modelling and Lettering to Website Designs. I’m now working to add data visualisation and into my skill set, I hope I don’t totally suck at it!"
  },
  {
    "objectID": "posts/My-name-is-Immortal/Index.html#my-first-piece-of-r-code",
    "href": "posts/My-name-is-Immortal/Index.html#my-first-piece-of-r-code",
    "title": "Day 1",
    "section": "My First Piece of R-code",
    "text": "My First Piece of R-code\nI’m doing this!!!!!\n\nlibrary (tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary (ggformula)\n\nLoading required package: scales\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nLoading required package: ggridges\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary (babynames)\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(knitr)\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\n\n\nGetting a list of all baby names in the USA from the year 1880\n\nbabynames\n\n# A tibble: 1,924,665 × 5\n    year sex   name          n   prop\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;  &lt;dbl&gt;\n 1  1880 F     Mary       7065 0.0724\n 2  1880 F     Anna       2604 0.0267\n 3  1880 F     Emma       2003 0.0205\n 4  1880 F     Elizabeth  1939 0.0199\n 5  1880 F     Minnie     1746 0.0179\n 6  1880 F     Margaret   1578 0.0162\n 7  1880 F     Ida        1472 0.0151\n 8  1880 F     Alice      1414 0.0145\n 9  1880 F     Bertha     1320 0.0135\n10  1880 F     Sarah      1288 0.0132\n# ℹ 1,924,655 more rows\n\n\n\n\n\nFiltering the presence of my name i.e. Sneha and creating a line graph with this data\n\nbabynames %&gt;% filter (name==\"Sneha\")\n\n# A tibble: 43 × 5\n    year sex   name      n       prop\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt;      &lt;dbl&gt;\n 1  1975 F     Sneha     9 0.00000577\n 2  1976 F     Sneha     7 0.00000445\n 3  1977 F     Sneha     9 0.00000547\n 4  1978 F     Sneha     9 0.00000548\n 5  1979 F     Sneha     6 0.00000348\n 6  1980 F     Sneha     7 0.00000393\n 7  1981 F     Sneha     6 0.00000336\n 8  1982 F     Sneha     8 0.00000441\n 9  1983 F     Sneha     9 0.00000503\n10  1984 F     Sneha    14 0.00000777\n# ℹ 33 more rows\n\n\n\nbabynames %&gt;% filter(name==\"Sneha\") %&gt;% gf_line(n~year)\n\n\n\n\n\n\n\n\n\n\nFiltering the presence of the name “Trisha” and creating a line graph with this data\n\nbabynames %&gt;% filter (name==\"Trisha\")\n\n# A tibble: 84 × 5\n    year sex   name       n       prop\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  &lt;int&gt;      &lt;dbl&gt;\n 1  1934 F     Trisha     5 0.00000462\n 2  1943 F     Trisha     5 0.00000348\n 3  1944 F     Trisha    33 0.0000242 \n 4  1945 F     Trisha    46 0.0000342 \n 5  1946 F     Trisha    56 0.0000347 \n 6  1947 F     Trisha    32 0.0000176 \n 7  1948 F     Trisha    29 0.0000166 \n 8  1949 F     Trisha    28 0.0000160 \n 9  1950 F     Trisha    36 0.0000205 \n10  1951 F     Trisha    50 0.0000271 \n# ℹ 74 more rows\n\n\n\nbabynames %&gt;% filter(name==\"Trisha\") %&gt;% gf_line(n~year)\n\n\n\n\n\n\n\n\n\n\nFiltering the presence of the name “Sarah” and creating a line graph with this data\n\nbabynames %&gt;% filter (name==\"Sarah\" | name==\"Sara\") \n\n# A tibble: 487 × 5\n    year sex   name      n      prop\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt;     &lt;dbl&gt;\n 1  1880 F     Sarah  1288 0.0132   \n 2  1880 F     Sara    165 0.00169  \n 3  1881 F     Sarah  1226 0.0124   \n 4  1881 F     Sara    147 0.00149  \n 5  1882 F     Sarah  1410 0.0122   \n 6  1882 F     Sara    180 0.00156  \n 7  1883 F     Sarah  1359 0.0113   \n 8  1883 F     Sara    183 0.00152  \n 9  1883 M     Sarah     7 0.0000622\n10  1884 F     Sarah  1518 0.0110   \n# ℹ 477 more rows\n\n\n\nbabynames %&gt;% filter(name==\"Sarah\" | name==\"Sara\") %&gt;% gf_line(n~year)\n\n\n\n\n\n\n\n\n\n\nGlimpse:\n\nbabynames %&gt;% dplyr::glimpse()\n\nRows: 1,924,665\nColumns: 5\n$ year &lt;dbl&gt; 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880,…\n$ sex  &lt;chr&gt; \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", …\n$ name &lt;chr&gt; \"Mary\", \"Anna\", \"Emma\", \"Elizabeth\", \"Minnie\", \"Margaret\", \"Ida\",…\n$ n    &lt;int&gt; 7065, 2604, 2003, 1939, 1746, 1578, 1472, 1414, 1320, 1288, 1258,…\n$ prop &lt;dbl&gt; 0.07238359, 0.02667896, 0.02052149, 0.01986579, 0.01788843, 0.016…\n\n\n\nbabynames_modified &lt;- babynames %&gt;%\n  dplyr::mutate(\n    sex = as_factor(sex),\n  )\nglimpse(babynames_modified)\n\nRows: 1,924,665\nColumns: 5\n$ year &lt;dbl&gt; 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880,…\n$ sex  &lt;fct&gt; F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F,…\n$ name &lt;chr&gt; \"Mary\", \"Anna\", \"Emma\", \"Elizabeth\", \"Minnie\", \"Margaret\", \"Ida\",…\n$ n    &lt;int&gt; 7065, 2604, 2003, 1939, 1746, 1578, 1472, 1414, 1320, 1288, 1258,…\n$ prop &lt;dbl&gt; 0.07238359, 0.02667896, 0.02052149, 0.01986579, 0.01788843, 0.016…\n\n\n\nbabynames_modified %&gt;% mosaic::inspect()\n\n\ncategorical variables:  \n  name     class levels       n missing\n1  sex    factor      2 1924665       0\n2 name character  97310 1924665       0\n                                   distribution\n1 F (59.1%), M (40.9%)                         \n2 Francis (0%), James (0%) ...                 \n\nquantitative variables:  \n  name   class      min        Q1    median        Q3          max         mean\n1 year numeric 1.88e+03 1.951e+03 1.985e+03 2.003e+03 2.017000e+03 1.974851e+03\n2    n integer 5.00e+00 7.000e+00 1.200e+01 3.200e+01 9.968600e+04 1.808733e+02\n3 prop numeric 2.26e-06 3.870e-06 7.300e-06 2.288e-05 8.154561e-02 1.362963e-04\n            sd       n missing\n1 3.402948e+01 1924665       0\n2 1.533337e+03 1924665       0\n3 1.151693e-03 1924665       0\n\n\n\nbabynames_modified %&gt;% skimr::skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n1924665\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nfactor\n1\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nname\n0\n1\n2\n15\n0\n97310\n0\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nsex\n0\n1\nFALSE\n2\nF: 1138293, M: 786372\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nyear\n0\n1\n1974.85\n34.03\n1880\n1951\n1985\n2003\n2017.00\n▁▂▃▅▇\n\n\nn\n0\n1\n180.87\n1533.34\n5\n7\n12\n32\n99686.00\n▇▁▁▁▁\n\n\nprop\n0\n1\n0.00\n0.00\n0\n0\n0\n0\n0.08\n▇▁▁▁▁"
  },
  {
    "objectID": "posts/day-3(2)/index.html",
    "href": "posts/day-3(2)/index.html",
    "title": "Day 3",
    "section": "",
    "text": "Today we worked on count of qualitative data. We also looked in creation of bar graph - data in lengths.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula)\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing"
  },
  {
    "objectID": "posts/day-3(2)/index.html#introduction",
    "href": "posts/day-3(2)/index.html#introduction",
    "title": "Day 3",
    "section": "",
    "text": "Today we worked on count of qualitative data. We also looked in creation of bar graph - data in lengths.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula)\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing"
  },
  {
    "objectID": "posts/day-3(2)/index.html#taxi-data-set",
    "href": "posts/day-3(2)/index.html#taxi-data-set",
    "title": "Day 3",
    "section": "Taxi data-set",
    "text": "Taxi data-set\n\ntaxi &lt;- read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/modeldata/taxi.csv\")\n\nRows: 10000 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): tip, company, local, dow, month\ndbl (3): rownames, distance, hour\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntaxi\n\n# A tibble: 10,000 × 8\n   rownames tip   distance company                      local dow   month  hour\n      &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;                        &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n 1        1 yes      17.2  Chicago Independents         no    Thu   Feb      16\n 2        2 yes       0.88 City Service                 yes   Thu   Mar       8\n 3        3 yes      18.1  other                        no    Mon   Feb      18\n 4        4 yes      20.7  Chicago Independents         no    Mon   Apr       8\n 5        5 yes      12.2  Chicago Independents         no    Sun   Mar      21\n 6        6 yes       0.94 Sun Taxi                     yes   Sat   Apr      23\n 7        7 yes      17.5  Flash Cab                    no    Fri   Mar      12\n 8        8 yes      17.7  other                        no    Sun   Jan       6\n 9        9 yes       1.85 Taxicab Insurance Agency Llc no    Fri   Apr      12\n10       10 yes       1.47 City Service                 no    Tue   Mar      14\n# ℹ 9,990 more rows\n\n\nWe first glimpse it to identify what variables need to be converted to factors.\n\ntaxi %&gt;% dplyr::glimpse()\n\nRows: 10,000\nColumns: 8\n$ rownames &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ tip      &lt;chr&gt; \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\"…\n$ distance &lt;dbl&gt; 17.19, 0.88, 18.11, 20.70, 12.23, 0.94, 17.47, 17.67, 1.85, 1…\n$ company  &lt;chr&gt; \"Chicago Independents\", \"City Service\", \"other\", \"Chicago Ind…\n$ local    &lt;chr&gt; \"no\", \"yes\", \"no\", \"no\", \"no\", \"yes\", \"no\", \"no\", \"no\", \"no\",…\n$ dow      &lt;chr&gt; \"Thu\", \"Thu\", \"Mon\", \"Mon\", \"Sun\", \"Sat\", \"Fri\", \"Sun\", \"Fri\"…\n$ month    &lt;chr&gt; \"Feb\", \"Mar\", \"Feb\", \"Apr\", \"Mar\", \"Apr\", \"Mar\", \"Jan\", \"Apr\"…\n$ hour     &lt;dbl&gt; 16, 8, 18, 8, 21, 23, 12, 6, 12, 14, 18, 11, 12, 19, 17, 13, …\n\n\nBefore we do mutate stuff into factors, it helps to know the number of levels of each variable, just to make sure. For do inspect and skim.\n\ntaxi %&gt;% mosaic::inspect()\n\n\ncategorical variables:  \n     name     class levels     n missing\n1     tip character      2 10000       0\n2 company character      7 10000       0\n3   local character      2 10000       0\n4     dow character      7 10000       0\n5   month character      4 10000       0\n                                   distribution\n1 yes (92.1%), no (7.9%)                       \n2 other (27.1%) ...                            \n3 no (81.2%), yes (18.8%)                      \n4 Thu (19.6%), Wed (17.5%), Tue (16.3%) ...    \n5 Apr (31.8%), Mar (31.4%), Feb (20.4%) ...    \n\nquantitative variables:  \n      name   class min      Q1  median        Q3     max        mean\n1 rownames numeric   1 2500.75 5000.50 7500.2500 10000.0 5000.500000\n2 distance numeric   0    0.94    1.78   15.5625    42.3    6.224144\n3     hour numeric   0   11.00   15.00   18.0000    23.0   14.177300\n           sd     n missing\n1 2886.895680 10000       0\n2    7.381397 10000       0\n3    4.359904 10000       0\n\n\n\ntaxi %&gt;% skimr::skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n10000\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ntip\n0\n1\n2\n3\n0\n2\n0\n\n\ncompany\n0\n1\n5\n28\n0\n7\n0\n\n\nlocal\n0\n1\n2\n3\n0\n2\n0\n\n\ndow\n0\n1\n3\n3\n0\n7\n0\n\n\nmonth\n0\n1\n3\n3\n0\n4\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nrownames\n0\n1\n5000.50\n2886.90\n1\n2500.75\n5000.50\n7500.25\n10000.0\n▇▇▇▇▇\n\n\ndistance\n0\n1\n6.22\n7.38\n0\n0.94\n1.78\n15.56\n42.3\n▇▁▂▁▁\n\n\nhour\n0\n1\n14.18\n4.36\n0\n11.00\n15.00\n18.00\n23.0\n▁▃▅▇▃\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable name\nDescription\nType of variable\n\n\n\n\ntip\nRepresents if the tip was given or not\nQualitative\n\n\ncompany\nThis variable indicates the taxi company or vendor that operates the vehicle.\nQualitative\n\n\nlocal\nThis variable may refer to whether the trip occurred within a local area or not\nQualitative\n\n\ndow\nhis variable represents the day of the week when the taxi ride took place\nQualitative\n\n\nmonth\nThis variable indicates the month during which the taxi ride occurred.\nQualitative\n\n\ndistance\nThis variable measures the total distance traveled during the taxi ride, usually expressed in miles\nQuantitative\n\n\nhour\nThis variable indicates the hour of the day when the trip started\nQuantitative\n\n\n\nTarget Variable: tip\nPredictor Variables: company, dow, local, month, hour\n\nAnd then we mutate. I feel like i scientist when i use the word mutate. We glimpse it again, cause why not.\n\n\ntaxi_modified &lt;- taxi %&gt;%\n  dplyr::mutate(\n    tip = factor(tip,\n      levels = c(\"no\", \"yes\"),\n      labels = c(\"no\", \"yes\"),\n      ordered = TRUE\n    ),\n    company = as_factor(company),\n    ##\n    dow = factor(dow,\n      levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"),\n      labels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"),\n      ordered = TRUE\n    ),\n    ##\n    local = factor(local,\n      levels = c(\"no\", \"yes\"),\n      labels = c(\"no\", \"yes\"),\n      ordered = TRUE\n    ),\n    ##\n    month = factor(month,\n      levels = c(\"Jan\", \"Feb\", \"Mar\", \"Apr\"),\n      labels = c(\"Jan\", \"Feb\", \"Mar\", \"Apr\"),\n      ordered = TRUE\n    ),\n    hour = as_factor(hour)\n  )\nglimpse(taxi_modified)\n\nRows: 10,000\nColumns: 8\n$ rownames &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ tip      &lt;ord&gt; yes, yes, yes, yes, yes, yes, yes, yes, yes, yes, yes, yes, y…\n$ distance &lt;dbl&gt; 17.19, 0.88, 18.11, 20.70, 12.23, 0.94, 17.47, 17.67, 1.85, 1…\n$ company  &lt;fct&gt; Chicago Independents, City Service, other, Chicago Independen…\n$ local    &lt;ord&gt; no, yes, no, no, no, yes, no, no, no, no, no, no, no, yes, no…\n$ dow      &lt;ord&gt; Thu, Thu, Mon, Mon, Sun, Sat, Fri, Sun, Fri, Tue, Tue, Sun, W…\n$ month    &lt;ord&gt; Feb, Mar, Feb, Apr, Mar, Apr, Mar, Jan, Apr, Mar, Mar, Apr, A…\n$ hour     &lt;fct&gt; 16, 8, 18, 8, 21, 23, 12, 6, 12, 14, 18, 11, 12, 19, 17, 13, …\n\n\n\nq1. Do more people tip than not?\n\ngf_bar(~tip, data = taxi_modified) %&gt;%\n  gf_labs(title = \"Counts of Tips\")\n\n\n\n\n\n\n\n\nLook that that! A vast majority of the lot, are people who tip!\n\n\nq2. Does the tip depend upon whether the trip is local or not?\nIn a dodged bar chart one variable is in the x- axis, but the y axis has the count of another variable. In this way we acquire counts of different levels of a qualitative data broken down by levels of another qualitative variable side by side, making it easy to compare.\n\ntaxi_modified %&gt;%\n  gf_bar(~local,\n    fill = ~tip,\n    position = \"dodge\"\n  ) %&gt;%\n  gf_labs(title = \"Dodged Bar Chart\" ,\n    subtitle = \"Proof that i know how to write subtitles\")%&gt;%\n  gf_refine(scale_fill_manual(values = c(\"turquoise\", \"salmon\")))\n\n\n\n\n\n\n\n\nA stacked bar looks very similar to a dodged chart, but counts of both levels are on top of each other. I like this one better, it looks neater, but in my opinion if the counts of multiple levels of one paramter are closeby values, it would be more practical to use a dodged bar.\n\ntaxi_modified %&gt;%\n  gf_bar(~local,\n    fill = ~tip,\n    position = \"stack\"\n  ) %&gt;%\n  gf_labs(\n    title = \"Stacked Bar Chart\",\n    subtitle = \"A sandwiched version of the last one!\"\n  )%&gt;%\n  gf_refine(scale_fill_manual(values = c(\"turquoise\", \"salmon\")))\n\n\n\n\n\n\n\n\nLooking at these, while we can spot the number of tips and lack of tips the locals and non-locals contributed- there are a lot more non local tips than local ones and in quantity, they do get most of their tips from non-locals.\n\nBut we can’t definitely say that non-locals tend to tip more certainly, it could only appear so beacuse the non-local trips are so much more. To find this, we will have to find the difference in ratios by using position = fill.\n\n\ntaxi_modified %&gt;%\n  gf_bar(~local,\n    fill = ~tip,\n    position = \"fill\"\n  ) %&gt;%\n  gf_labs(\n    title = \"Filled Bar Chart\",\n    subtitle = \"Shows Per group differences in Proportions!\"\n  )%&gt;%\n  gf_refine(scale_fill_manual(values = c(\"turquoise\", \"salmon\")))\n\n\n\n\n\n\n\n\nWe can now observe that locals tend to tip lesser than the non-locals.\n\n\nq3. Do some cab companies get more tips than others?\n\ntaxi_modified %&gt;%\n  gf_bar(~company, fill = ~tip, position = \"dodge\") %&gt;%\n  gf_labs(title = \"Dodged Bar Chart\") %&gt;%\n  gf_theme(theme(axis.text.x = element_text(size = 6, angle = 45, hjust = 1)))%&gt;%\n  gf_refine(scale_fill_manual(values = c(\"turquoise\", \"salmon\")))\n\n\n\n\n\n\n\n\nOther gets the most count of trips but do they get the most number of tips in ratio?\n\ntaxi_modified %&gt;%\n  gf_props(~company, fill = ~tip, position = \"fill\") %&gt;%\n  gf_labs(\n    title = \"Filled Bar Chart\",\n    subtitle = \"Shows Per group differences in Proportions!\"\n  ) %&gt;%\n  gf_theme(theme(axis.text.x = element_text(size = 6, angle = 45, hjust = 1)))%&gt;%\n  gf_refine(scale_fill_manual(values = c(\"turquoise\", \"salmon\")))\n\n\n\n\n\n\n\n\nIt appears so that flash cabs is the company that gets the least amount of tips. While Chicago gets the most number of tips per-group proportion.\n\n\nq4. Does a tip depend upon the hour of the day? At which are are the tips highest and lowest?\n\ngf_bar(~hour, fill = ~tip, data = taxi_modified) %&gt;%\n  gf_labs(title = \"Counts of Tips by Hour\")%&gt;%\n  gf_refine(scale_fill_manual(values = c(\"turquoise\", \"salmon\")))\n\n\n\n\n\n\n\n\nThe count of tips are highest are the 17th hour while lowest is at the 4th hour.\n\ngf_bar(~hour, fill = ~tip, position = \"fill\", data = taxi_modified) %&gt;%\n  gf_labs(title = \"Counts of Tips by Hour in proportion\")%&gt;%\n  gf_refine(scale_fill_manual(values = c(\"turquoise\", \"salmon\")))\n\n\n\n\n\n\n\n\nPeople are most likely to tip at 2nd and 4th hour and least at 8th, 15th and 23rd hour.\n\n\nq5. Does a tip depend upon the day of the week? At which day are the tips highest and lowest?\n\ngf_bar(~dow, fill = ~tip, data = taxi_modified) %&gt;%\n  gf_labs(title = \"Counts of Tips by Day of Week\")%&gt;%\n  gf_refine(scale_fill_manual(values = c(\"turquoise\", \"salmon\")))\n\n\n\n\n\n\n\n\nThe highest count of tips are on Thursdays and lowest is on Sundays. The count of tips thend to be the highest in weekdays and lesser in weekends\n\ngf_bar(~dow, fill = ~tip, data = taxi_modified, position = \"fill\") %&gt;%\n  gf_labs(title = \"Counts of Tips by Day of Week in proportion\")%&gt;%\n  gf_refine(scale_fill_manual(values = c(\"turquoise\", \"salmon\")))\n\n\n\n\n\n\n\n\nPeople are most likely to tip on Sundays and least likely to tip on Fridays.\n\n\nq6. At which month are the tips highest and lowest among the 4 recorded?\n\ngf_bar(~month, fill = ~tip, data = taxi_modified) %&gt;%\n  gf_labs(title = \"Counts of Tips by Month\")%&gt;%\n  gf_refine(scale_fill_manual(values = c(\"turquoise\", \"salmon\")))\n\n\n\n\n\n\n\n\nThe highest count of tips is on April and lowest is on January.\n\ngf_bar(~month, fill = ~tip, data = taxi_modified, position = \"fill\") %&gt;%\n  gf_labs(title = \"Counts of Tips by Month in proportion\")%&gt;%\n  gf_refine(scale_fill_manual(values = c(\"turquoise\", \"salmon\")))\n\n\n\n\n\n\n\n\nPeople are least likely to tip in April and most likely to tip in January.\n\n\nCounts of Tips by Day of Week and Month\n\nHere, we are obtaining a total 7 graphs, each for a day week. Each graph has 4 bars each, with month as the x axis indicating- for each day, in what month, the count of tips is observed.\n\n\ngf_bar(~ month | dow, fill = ~tip, data = taxi_modified) %&gt;%\n  gf_labs(title = \"Counts of Tips by Day of Week and Month\")%&gt;%\n  gf_refine(scale_fill_manual(values = c(\"turquoise\", \"salmon\")))\n\n\n\n\n\n\n\n\n\n\nCounts of Tips by Hour and Day of Week\n\ngf_bar(~ hour | dow, fill = ~tip, data = taxi_modified) %&gt;%\n  gf_labs(\n    title = \"Counts of Tips by Hour and Day of Week\"\n  )%&gt;%\n  gf_refine(scale_fill_manual(values = c(\"turquoise\", \"salmon\")))"
  },
  {
    "objectID": "posts/day-3(2)/index.html#addiction-healthcare-data-set",
    "href": "posts/day-3(2)/index.html#addiction-healthcare-data-set",
    "title": "Day 3",
    "section": "Addiction healthcare data-set",
    "text": "Addiction healthcare data-set\n\ndata(\"HELPrct\")\n\n\nObtaining the count of of each substance\n\nHELPrct %&gt;% gf_bar(~substance)\n\n\n\n\n\n\n\n\nBased on this data, more people are addicted to alcohol than cocaine or heroin.\n\n\nPlotting the count of substance based on gender\n\nHELPrct %&gt;% gf_bar(~substance,fill = ~sex)%&gt;% \n  gf_refine(scale_fill_manual(values = c(\"turquoise\", \"salmon\")))\n\n\n\n\n\n\n\n\nFor all 3 substances, more men in count seem to be addicted than women."
  },
  {
    "objectID": "posts/day-3(2)/index.html#banned-books-data-set",
    "href": "posts/day-3(2)/index.html#banned-books-data-set",
    "title": "Day 3",
    "section": "Banned Books data-set",
    "text": "Banned Books data-set\n\nbanned &lt;- read_csv(\"../../data/banned-author-title.csv\")\n\nRows: 1586 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): Author, Title, Type of Ban, State, District, Date of Challenge/Remo...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nbanned\n\n# A tibble: 1,586 × 7\n   Author              Title `Type of Ban` State District Date of Challenge/Re…¹\n   &lt;chr&gt;               &lt;chr&gt; &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;                 \n 1 Àbíké-Íyímídé, Far… Ace … Banned from … Flor… Indian … Nov-21                \n 2 Acevedo, Elizabeth  Clap… Banned from … Penn… Central… Sep-21                \n 3 Acevedo, Elizabeth  The … Banned from … Flor… Indian … Nov-21                \n 4 Acevedo, Elizabeth  The … Banned from … New … Marlbor… Feb-22                \n 5 Acevedo, Elizabeth  The … Banned Pendi… Texas Frederi… Mar-22                \n 6 Acevedo, Elizabeth  The … Banned Pendi… Virg… New Ken… Oct-21                \n 7 Aciman, André       Call… Banned Pendi… Virg… Spotsly… Nov-21                \n 8 Acito, Marc         How … Banned Pendi… Flor… Indian … Nov-21                \n 9 Adeyoha, Koja       47,0… Banned from … Penn… Central… Sep-21                \n10 Adichie, Chimamand… Half… Banned from … Mich… Hudsonv… Jan-22                \n# ℹ 1,576 more rows\n# ℹ abbreviated name: ¹​`Date of Challenge/Removal`\n# ℹ 1 more variable: `Origin of Challenge` &lt;chr&gt;\n\n\n\nbanned %&gt;% dplyr::glimpse()\n\nRows: 1,586\nColumns: 7\n$ Author                      &lt;chr&gt; \"Àbíké-Íyímídé, Faridah\", \"Acevedo, Elizab…\n$ Title                       &lt;chr&gt; \"Ace of Spades\", \"Clap When You Land\", \"Th…\n$ `Type of Ban`               &lt;chr&gt; \"Banned from Libraries and Classrooms\", \"B…\n$ State                       &lt;chr&gt; \"Florida\", \"Pennsylvania\", \"Florida\", \"New…\n$ District                    &lt;chr&gt; \"Indian River County School\", \"Central Yor…\n$ `Date of Challenge/Removal` &lt;chr&gt; \"Nov-21\", \"Sep-21\", \"Nov-21\", \"Feb-22\", \"M…\n$ `Origin of Challenge`       &lt;chr&gt; \"Administrator\", \"Administrator\", \"Adminis…\n\n\n\nbanned %&gt;% mosaic::inspect()\n\n\ncategorical variables:  \n                       name     class levels    n missing\n1                    Author character    797 1586       0\n2                     Title character   1145 1586       0\n3               Type of Ban character      4 1586       0\n4                     State character     26 1586       0\n5                  District character     86 1586       0\n6 Date of Challenge/Removal character     12 1586       0\n7       Origin of Challenge character      2 1586       0\n                                   distribution\n1 Kobabe, Maia (1.9%) ...                      \n2 Gender Queer: A Memoir (1.9%) ...            \n3 Banned Pending Investigation (46.1%) ...     \n4 Texas (45%), Pennsylvania (28.8%) ...        \n5 Central York (27.8%) ...                     \n6 Sep-21 (28.8%), Dec-21 (28.3%) ...           \n7 Administrator (95.6%) ...                    \n\n\n\nType of ban, State, District, Date of challenge and origin of challenge can be declared as factors.\n\n\nWhat could the target variable be?\nI guess it could be type of ban - understanding it could help predict if a book will be fully banned, temporarily banned, or restricted or with State/district, we could understand which states or districts are more likely to challenge books.\n\nbanned_modified &lt;- banned %&gt;%\n  dplyr::mutate(\n    `Type of Ban` = as_factor(`Type of Ban`),\n    State = as_factor(State),\n    District = as_factor(District),\n    `Date of Challenge/Removal` = as_factor(`Date of Challenge/Removal`),\n    `Origin of Challenge` = as_factor(`Origin of Challenge`),\n  )\nglimpse(banned_modified)\n\nRows: 1,586\nColumns: 7\n$ Author                      &lt;chr&gt; \"Àbíké-Íyímídé, Faridah\", \"Acevedo, Elizab…\n$ Title                       &lt;chr&gt; \"Ace of Spades\", \"Clap When You Land\", \"Th…\n$ `Type of Ban`               &lt;fct&gt; Banned from Libraries and Classrooms, Bann…\n$ State                       &lt;fct&gt; Florida, Pennsylvania, Florida, New York, …\n$ District                    &lt;fct&gt; Indian River County School, Central York, …\n$ `Date of Challenge/Removal` &lt;fct&gt; Nov-21, Sep-21, Nov-21, Feb-22, Mar-22, Oc…\n$ `Origin of Challenge`       &lt;fct&gt; Administrator, Administrator, Administrato…\n\n\n\nbanned_modified %&gt;% mosaic::inspect()\n\n\ncategorical variables:  \n                       name     class levels    n missing\n1                    Author character    797 1586       0\n2                     Title character   1145 1586       0\n3               Type of Ban    factor      4 1586       0\n4                     State    factor     26 1586       0\n5                  District    factor     86 1586       0\n6 Date of Challenge/Removal    factor     12 1586       0\n7       Origin of Challenge    factor      2 1586       0\n                                   distribution\n1 Kobabe, Maia (1.9%) ...                      \n2 Gender Queer: A Memoir (1.9%) ...            \n3 Banned Pending Investigation (46.1%) ...     \n4 Texas (45%), Pennsylvania (28.8%) ...        \n5 Central York (27.8%) ...                     \n6 Sep-21 (28.8%), Dec-21 (28.3%) ...           \n7 Administrator (95.6%) ...                    \n\n\n\nbanned_modified %&gt;% skimr::skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n1586\n\n\nNumber of columns\n7\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nfactor\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nAuthor\n0\n1\n7\n29\n0\n797\n0\n\n\nTitle\n0\n1\n2\n155\n0\n1145\n0\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nType of Ban\n0\n1\nFALSE\n4\nBan: 731, Ban: 474, Ban: 197, Ban: 184\n\n\nState\n0\n1\nFALSE\n26\nTex: 713, Pen: 456, Flo: 204, Okl: 43\n\n\nDistrict\n0\n1\nFALSE\n86\nCen: 441, Nor: 435, Ind: 161, Gra: 131\n\n\nDate of Challenge/Removal\n0\n1\nFALSE\n12\nSep: 456, Dec: 449, Nov: 227, Jan: 178\n\n\nOrigin of Challenge\n0\n1\nFALSE\n2\nAdm: 1517, For: 69\n\n\n\n\n\n\n\nTARGET VARIABLE: State\n\nq1. Which state has the most amount of banned books?\n\ngf_bar(~State, data = banned_modified) %&gt;%\n  gf_labs(title = \"Counts of States\")%&gt;%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n\n\n\n\n\n\n\n\nAs expected, Texas leads the nation in the number of banned books, with Pennsylvania following in second place.\n\nSince there is data on so many states, like we did on day 4, i want to filter it to be only 10 states with the most amount of banned books.\n\n\ntop_states &lt;- banned_modified %&gt;%\n  group_by(State) %&gt;%                   # Group by state\n  summarize(n = n()) %&gt;%                # Count banned books per state\n  slice_max(n, n = 10) %&gt;%                # Select the top 5 states\n  pull(State)                           # Extract the state names\n\n\ntop_10_states_data &lt;- banned_modified %&gt;%\n  filter(State %in% top_states)\n\n\ntop_10_states_data\n\n# A tibble: 1,524 × 7\n   Author              Title `Type of Ban` State District Date of Challenge/Re…¹\n   &lt;chr&gt;               &lt;chr&gt; &lt;fct&gt;         &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt;                 \n 1 Àbíké-Íyímídé, Far… Ace … Banned from … Flor… Indian … Nov-21                \n 2 Acevedo, Elizabeth  Clap… Banned from … Penn… Central… Sep-21                \n 3 Acevedo, Elizabeth  The … Banned from … Flor… Indian … Nov-21                \n 4 Acevedo, Elizabeth  The … Banned Pendi… Texas Frederi… Mar-22                \n 5 Acevedo, Elizabeth  The … Banned Pendi… Virg… New Ken… Oct-21                \n 6 Aciman, André       Call… Banned Pendi… Virg… Spotsly… Nov-21                \n 7 Acito, Marc         How … Banned Pendi… Flor… Indian … Nov-21                \n 8 Adeyoha, Koja       47,0… Banned from … Penn… Central… Sep-21                \n 9 Agell, Charlotte    The … Banned from … Texas North E… Dec-21                \n10 Ahmadi, Arvin       How … Banned Pendi… Texas North E… Dec-21                \n# ℹ 1,514 more rows\n# ℹ abbreviated name: ¹​`Date of Challenge/Removal`\n# ℹ 1 more variable: `Origin of Challenge` &lt;fct&gt;\n\n\n\n\nq2. What is the correlation between type of ban and the state it is challenged in?\n\ntop_10_states_data %&gt;%\n  gf_bar(~State,\n    fill = ~`Type of Ban`,\n    position = \"stack\"\n  ) %&gt;%\n  gf_labs(title = \"Staked Bar Chart\" ,\n    subtitle = \"Type of ban by state\")%&gt;%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n\n\n\n\n\n\n\n\nIt seems that almost all books banned in Pennsylvania are banned in Classrooms and in Texas, while most of them are banned from a pending investigation, there is a significant section of it banned from libraries and classrooms\n\n\nq3. Does the ban depend on the Origin of Challenge?\n\ntop_10_states_data %&gt;%\n  gf_bar(~State,\n    fill = ~`Origin of Challenge`,\n    position = \"stack\"\n  ) %&gt;%\n  gf_labs(title = \"Staked Bar Chart\" ,\n    subtitle = \"Origin of Challenge by state\")%&gt;%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n\n\n\n\n\n\n\n\nMost bans evrywhere were raised by the administration. Interestingly, all the books banned in Pennsylvania have been challenged by the administrator. In Texas, a large majority has been challenged by Administrator but there is still a portion of it challenged formally. All banned books in Missouri were challenged formally, how surprising!\n\n\nq4. Is there a correlation between the type of ban and the Origin of challenge?\n\ngf_bar(~`Origin of Challenge` | `Type of Ban`, fill = ~State, data = top_10_states_data) %&gt;%\n  gf_labs(title = \"Counts of Ban by State by type of ban and origin\")\n\n\n\n\n\n\n\n\n\ngf_bar(~`Origin of Challenge` | State, fill = ~`Type of Ban`, data = top_10_states_data) %&gt;%\n  gf_labs(title = \"Counts of Types of Ban by State and Origin\")%&gt;%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n\n\n\n\n\n\n\n\nYou would expect that only all books whose origin was formal would be the ones banned in classrooms (over protective parents exist all over the world) but surprising, From what i can see, in Texas, most books formally banned are banned from libraries (a few also banned from classrooms and libraries) and the ones banned in Missouri are mostly banned pending investigation.\n\n\nq5. In which month of which year were most bans challenged?\n\ngf_bar(~`Date of Challenge/Removal`, data = banned_modified) %&gt;%\n  gf_labs(title = \"Counts of bans every month\")%&gt;%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n\n\n\n\n\n\n\n\nMost books were banned during September and December.\n\ntop_10_states_data %&gt;%\n  gf_bar(~State,\n    fill = ~`Date of Challenge/Removal`,\n    position = \"stack\"\n  ) %&gt;%\n  gf_labs(title = \"Staked Bar Chart\" ,\n    subtitle = \"Origin of Challenge by state\")%&gt;%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n\n\n\n\n\n\n\n\nFrom this bar, it is clear that every state has one month where most of there bans are imposed. For Texas it’s mostly in December, some in January, fewer in March, fall and November. For Pennsylvania, it’s moslty all in September. For Florida it’s mostly in November.\n\n\nq6. Is there a correlation between the type of ban and when it was challenged?\n\ngf_bar(~`Type of Ban` | `Date of Challenge/Removal`, fill = ~State, data = top_10_states_data) %&gt;%\n  gf_labs(title = \"Counts of Types of Ban by State and Origin\")%&gt;%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n\n\n\n\n\n\n\n\nTo no surprise, there does not seem to be any correlation between type of ban and the month it was challenged in.\n\n\nq7. Is there a correlation between the origin of ban and when it was challenged?\nI know it’s a long shot.\n\ngf_bar(~`Origin of Challenge` | State, fill = ~`Date of Challenge/Removal`, data = top_10_states_data) %&gt;%\n  gf_labs(title = \"Counts of Types of Ban by State and Origin\")%&gt;%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n\n\n\n\n\n\n\n\n\n\nq8. Which author has the honor of being the most banned?\n\ntop_author &lt;- banned_modified %&gt;%\n  count(Author) %&gt;%\n  slice_max(n, n = 4)  \n\ntop_author\n\n# A tibble: 4 × 2\n  Author                 n\n  &lt;chr&gt;              &lt;int&gt;\n1 Kobabe, Maia          30\n2 Hopkins, Ellen        27\n3 Johnson, George M.    21\n4 Do, Anh               17"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fundamentals of Statistics and Data Analysis",
    "section": "",
    "text": "Day 4\n\n\n\n\n\n\nquantities\n\n\nhistogram\n\n\n\n\n\n\n\n\n\nOct 4, 2024\n\n\nSneha Manu Jacob\n\n\n\n\n\n\n\n\n\n\n\n\nDay 3\n\n\n\n\n\n\ncounts\n\n\nBar-graph\n\n\ntaxi\n\n\naddiction\n\n\nbanned-books\n\n\n\n\n\n\n\n\n\nOct 3, 2024\n\n\nSneha Manu Jacob\n\n\n\n\n\n\n\n\n\n\n\n\nDay 2\n\n\n\n\n\n\nsummaries\n\n\nmgp-data\n\n\nmath-anxiety-data\n\n\n\n\n\n\n\n\n\nSep 27, 2024\n\n\nSneha Jacob\n\n\n\n\n\n\n\n\n\n\n\n\nDay 1\n\n\n\n\n\n\nintro\n\n\nbabyname-analysis\n\n\nline-graph\n\n\n\n\n\n\n\n\n\nSep 26, 2024\n\n\nSneha Jacob\n\n\n\n\n\n\n\n\n\n\n\n\n Facing the Abyss - WorkFLow\n\n\n\n\n\n\nEDA\n\n\nWorkflow\n\n\nDescriptive\n\n\n\nA complete EDA Workflow\n\n\n\n\n\nOct 21, 2023\n\n\nArvind V\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/Day-2/index.html",
    "href": "posts/Day-2/index.html",
    "title": "Day 2",
    "section": "",
    "text": "Throwing away data to grasp it. I am trying to reduce data into a summarized form."
  },
  {
    "objectID": "posts/Day-2/index.html#introduction",
    "href": "posts/Day-2/index.html#introduction",
    "title": "Day 2",
    "section": "",
    "text": "Throwing away data to grasp it. I am trying to reduce data into a summarized form."
  },
  {
    "objectID": "posts/Day-2/index.html#r-code",
    "href": "posts/Day-2/index.html#r-code",
    "title": "Day 2",
    "section": "R-code:",
    "text": "R-code:\n\nnote to self: don’t forget to put the label!!!!!\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(knitr)\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows"
  },
  {
    "objectID": "posts/Day-2/index.html#the-mpg-data-set-car-stuff",
    "href": "posts/Day-2/index.html#the-mpg-data-set-car-stuff",
    "title": "Day 2",
    "section": "The mpg data-set (car stuff):",
    "text": "The mpg data-set (car stuff):\n\nmpg\n\n# A tibble: 234 × 11\n   manufacturer model      displ  year   cyl trans drv     cty   hwy fl    class\n   &lt;chr&gt;        &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n 1 audi         a4           1.8  1999     4 auto… f        18    29 p     comp…\n 2 audi         a4           1.8  1999     4 manu… f        21    29 p     comp…\n 3 audi         a4           2    2008     4 manu… f        20    31 p     comp…\n 4 audi         a4           2    2008     4 auto… f        21    30 p     comp…\n 5 audi         a4           2.8  1999     6 auto… f        16    26 p     comp…\n 6 audi         a4           2.8  1999     6 manu… f        18    26 p     comp…\n 7 audi         a4           3.1  2008     6 auto… f        18    27 p     comp…\n 8 audi         a4 quattro   1.8  1999     4 manu… 4        18    26 p     comp…\n 9 audi         a4 quattro   1.8  1999     4 auto… 4        16    25 p     comp…\n10 audi         a4 quattro   2    2008     4 manu… 4        20    28 p     comp…\n# ℹ 224 more rows\n\n\n\nmaking it look fancy. Arvind wrote this, i only added it here cause i wanted the full form of all columns cause i don’t know car stuff.\n\n\nmpg %&gt;%\n  head(10) %&gt;%\n  kbl(\n    # add Human Readable column names\n    col.names = c(\n      \"Manufacturer\", \"Model\", \"Engine\\nDisplacement\",\n      \"Model\\n Year\", \"Cylinders\", \"Transmission\",\n      \"Drivetrain\", \"City\\n Mileage\", \"Highway\\n Mileage\",\n      \"Fuel\", \"Class\\nOf\\nVehicle\"\n    ),\n    caption = \"MPG Dataset\"\n  ) %&gt;%\n  kable_styling(\n    bootstrap_options = c(\n      \"striped\", \"hover\",\n      \"condensed\", \"responsive\"\n    ),\n    full_width = F, position = \"center\"\n  )\n\n\n\nMPG Dataset\n\n\nManufacturer\nModel\nEngine Displacement\nModel Year\nCylinders\nTransmission\nDrivetrain\nCity Mileage\nHighway Mileage\nFuel\nClass Of Vehicle\n\n\n\n\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact\n\n\naudi\na4\n2.8\n1999\n6\nmanual(m5)\nf\n18\n26\np\ncompact\n\n\naudi\na4\n3.1\n2008\n6\nauto(av)\nf\n18\n27\np\ncompact\n\n\naudi\na4 quattro\n1.8\n1999\n4\nmanual(m5)\n4\n18\n26\np\ncompact\n\n\naudi\na4 quattro\n1.8\n1999\n4\nauto(l5)\n4\n16\n25\np\ncompact\n\n\naudi\na4 quattro\n2.0\n2008\n4\nmanual(m6)\n4\n20\n28\np\ncompact\n\n\n\n\n\n\n\n\n\nGlimpse:\n\nmpg %&gt;% dplyr::glimpse()\n\nRows: 234\nColumns: 11\n$ manufacturer &lt;chr&gt; \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"…\n$ model        &lt;chr&gt; \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4 quattro\", \"…\n$ displ        &lt;dbl&gt; 1.8, 1.8, 2.0, 2.0, 2.8, 2.8, 3.1, 1.8, 1.8, 2.0, 2.0, 2.…\n$ year         &lt;int&gt; 1999, 1999, 2008, 2008, 1999, 1999, 2008, 1999, 1999, 200…\n$ cyl          &lt;int&gt; 4, 4, 4, 4, 6, 6, 6, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, …\n$ trans        &lt;chr&gt; \"auto(l5)\", \"manual(m5)\", \"manual(m6)\", \"auto(av)\", \"auto…\n$ drv          &lt;chr&gt; \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"4\", \"4\", \"4\", \"4\", \"4…\n$ cty          &lt;int&gt; 18, 21, 20, 21, 16, 18, 18, 18, 16, 20, 19, 15, 17, 17, 1…\n$ hwy          &lt;int&gt; 29, 29, 31, 30, 26, 26, 27, 26, 25, 28, 27, 25, 25, 25, 2…\n$ fl           &lt;chr&gt; \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p…\n$ class        &lt;chr&gt; \"compact\", \"compact\", \"compact\", \"compact\", \"compact\", \"c…\n\n\n\n\n\n\n\n\n\n\nVariable name\nDescription\nType of variable\n\n\n\n\nmanufacturer\nRepresents the name of the company that produces the vehicle.\nQualitative\n\n\nmodel\nThis variable indicates the specific model of the vehicle produced by the manufacturer.\nQualitative\n\n\ndispl\nEngine Displacement: measures the engine’s size or capacity\nQuantitative\n\n\nyear\nIndicates the year in which the vehicle model was manufactured.\nQualitative\n\n\ncyl\nSpecifies the number of cylinders in the vehicle’s engine.\nQualitative\n\n\ntrans\nIndicates the type of transmission system used in the vehicle\nQualitative\n\n\ndrv\nDescribes how power is delivered to the wheels (e.g., front-wheel drive, rear-wheel drive, all-wheel drive)\nQualitative\n\n\ncty\nMeasures the fuel efficiency of the vehicle when driving in urban conditions\nQuantitative\n\n\nhwy\nMeasures fuel efficiency on highways\nQuantitative\n\n\nfl\nIndicates the type of fuel used by the vehicle\nQualitative\n\n\nclass\nCategorizes vehicles into different classes based on their size, purpose, or design\nQualitative\n\n\n\n\nThrough this glimpse, i find that cylinder is encoded as an int, and so it is considered a quantitative variable. i need to change it.\n\n\nmpg_modified &lt;- mpg %&gt;%\n  dplyr::mutate(\n    cyl = as_factor(cyl),\n    fl = as_factor(fl),\n    drv = as_factor(drv),\n    class = as_factor(class),\n    trans = as_factor(trans)\n  )\nglimpse(mpg_modified)\n\nRows: 234\nColumns: 11\n$ manufacturer &lt;chr&gt; \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"…\n$ model        &lt;chr&gt; \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4 quattro\", \"…\n$ displ        &lt;dbl&gt; 1.8, 1.8, 2.0, 2.0, 2.8, 2.8, 3.1, 1.8, 1.8, 2.0, 2.0, 2.…\n$ year         &lt;int&gt; 1999, 1999, 2008, 2008, 1999, 1999, 2008, 1999, 1999, 200…\n$ cyl          &lt;fct&gt; 4, 4, 4, 4, 6, 6, 6, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, …\n$ trans        &lt;fct&gt; auto(l5), manual(m5), manual(m6), auto(av), auto(l5), man…\n$ drv          &lt;fct&gt; f, f, f, f, f, f, f, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, r, …\n$ cty          &lt;int&gt; 18, 21, 20, 21, 16, 18, 18, 18, 16, 20, 19, 15, 17, 17, 1…\n$ hwy          &lt;int&gt; 29, 29, 31, 30, 26, 26, 27, 26, 25, 28, 27, 25, 25, 25, 2…\n$ fl           &lt;fct&gt; p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, r, …\n$ class        &lt;fct&gt; compact, compact, compact, compact, compact, compact, com…\n\n\n\n\nInspecting the data-set with mosaic and skimr\nA mosaic inspect of the mgp data-set only to see the difference between this and the newly created mpg_modified data set\n\nmpg %&gt;% mosaic::inspect()\n\n\ncategorical variables:  \n          name     class levels   n missing\n1 manufacturer character     15 234       0\n2        model character     38 234       0\n3        trans character     10 234       0\n4          drv character      3 234       0\n5           fl character      5 234       0\n6        class character      7 234       0\n                                   distribution\n1 dodge (15.8%), toyota (14.5%) ...            \n2 caravan 2wd (4.7%) ...                       \n3 auto(l4) (35.5%), manual(m5) (24.8%) ...     \n4 f (45.3%), 4 (44%), r (10.7%)                \n5 r (71.8%), p (22.2%), e (3.4%) ...           \n6 suv (26.5%), compact (20.1%) ...             \n\nquantitative variables:  \n   name   class    min     Q1 median     Q3  max        mean       sd   n\n1 displ numeric    1.6    2.4    3.3    4.6    7    3.471795 1.291959 234\n2  year integer 1999.0 1999.0 2003.5 2008.0 2008 2003.500000 4.509646 234\n3   cyl integer    4.0    4.0    6.0    8.0    8    5.888889 1.611534 234\n4   cty integer    9.0   14.0   17.0   19.0   35   16.858974 4.255946 234\n5   hwy integer   12.0   18.0   24.0   27.0   44   23.440171 5.954643 234\n  missing\n1       0\n2       0\n3       0\n4       0\n5       0\n\n\n\nmpg_modified %&gt;% mosaic::inspect()\n\n\ncategorical variables:  \n          name     class levels   n missing\n1 manufacturer character     15 234       0\n2        model character     38 234       0\n3          cyl    factor      4 234       0\n4        trans    factor     10 234       0\n5          drv    factor      3 234       0\n6           fl    factor      5 234       0\n7        class    factor      7 234       0\n                                   distribution\n1 dodge (15.8%), toyota (14.5%) ...            \n2 caravan 2wd (4.7%) ...                       \n3 4 (34.6%), 6 (33.8%), 8 (29.9%) ...          \n4 auto(l4) (35.5%), manual(m5) (24.8%) ...     \n5 f (45.3%), 4 (44%), r (10.7%)                \n6 r (71.8%), p (22.2%), e (3.4%) ...           \n7 suv (26.5%), compact (20.1%) ...             \n\nquantitative variables:  \n   name   class    min     Q1 median     Q3  max        mean       sd   n\n1 displ numeric    1.6    2.4    3.3    4.6    7    3.471795 1.291959 234\n2  year integer 1999.0 1999.0 2003.5 2008.0 2008 2003.500000 4.509646 234\n3   cty integer    9.0   14.0   17.0   19.0   35   16.858974 4.255946 234\n4   hwy integer   12.0   18.0   24.0   27.0   44   23.440171 5.954643 234\n  missing\n1       0\n2       0\n3       0\n4       0\n\n\n\nmpg_modified %&gt;% skimr::skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n234\n\n\nNumber of columns\n11\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nfactor\n5\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nmanufacturer\n0\n1\n4\n10\n0\n15\n0\n\n\nmodel\n0\n1\n2\n22\n0\n38\n0\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\ncyl\n0\n1\nFALSE\n4\n4: 81, 6: 79, 8: 70, 5: 4\n\n\ntrans\n0\n1\nFALSE\n10\naut: 83, man: 58, aut: 39, man: 19\n\n\ndrv\n0\n1\nFALSE\n3\nf: 106, 4: 103, r: 25\n\n\nfl\n0\n1\nFALSE\n5\nr: 168, p: 52, e: 8, d: 5\n\n\nclass\n0\n1\nFALSE\n7\nsuv: 62, com: 47, mid: 41, sub: 35\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ndispl\n0\n1\n3.47\n1.29\n1.6\n2.4\n3.3\n4.6\n7\n▇▆▆▃▁\n\n\nyear\n0\n1\n2003.50\n4.51\n1999.0\n1999.0\n2003.5\n2008.0\n2008\n▇▁▁▁▇\n\n\ncty\n0\n1\n16.86\n4.26\n9.0\n14.0\n17.0\n19.0\n35\n▆▇▃▁▁\n\n\nhwy\n0\n1\n23.44\n5.95\n12.0\n18.0\n24.0\n27.0\n44\n▅▅▇▁▁\n\n\n\n\n\n\n\nGroups within columns -\nWe can group a quantitative data based on different qualitative data-sets.\n\nHere i am finding the separate means of highway mileage for every separate level of cyl.\n\nmpg_modified %&gt;%\n  group_by(cyl) %&gt;%\n  summarize(average_hwy = mean(hwy), count = n())\n\n# A tibble: 4 × 3\n  cyl   average_hwy count\n  &lt;fct&gt;       &lt;dbl&gt; &lt;int&gt;\n1 4            28.8    81\n2 5            28.8     4\n3 6            22.8    79\n4 8            17.6    70\n\n\nThe most highway mileage is for 4 cylinders while the lowest is for 8 cylinders.\n\nYou can find mean based on 2 or more factors i.e. permutations and combinations of all factors\n\n\n\nSeparate means of highway mileage for every separate level of cyl and fuel.\n\nmpg_modified %&gt;%\n  group_by(cyl, fl) %&gt;%\n  summarize(average_hwy = mean(hwy), count = n())\n\n`summarise()` has grouped output by 'cyl'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 13 × 4\n# Groups:   cyl [4]\n   cyl   fl    average_hwy count\n   &lt;fct&gt; &lt;fct&gt;       &lt;dbl&gt; &lt;int&gt;\n 1 4     p            27.8    22\n 2 4     r            28.3    55\n 3 4     d            43       3\n 4 4     c            36       1\n 5 5     r            28.8     4\n 6 6     p            25.3    17\n 7 6     r            22.2    60\n 8 6     e            17       1\n 9 6     d            22       1\n10 8     p            20.8    13\n11 8     r            17.5    49\n12 8     e            12.7     7\n13 8     d            17       1\n\n\nThe highest mean highway mileage is for a cars with 4 cylinders with diesel fuel while the lowest is for electric cars with 6 cylinders.\n\n\nSeparate means of city mileage for every separate level of cyl and fuel.\n\nmpg_modified %&gt;%\n  group_by(cyl, fl) %&gt;%\n  summarize(average_cty = mean(cty), count = n())\n\n`summarise()` has grouped output by 'cyl'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 13 × 4\n# Groups:   cyl [4]\n   cyl   fl    average_cty count\n   &lt;fct&gt; &lt;fct&gt;       &lt;dbl&gt; &lt;int&gt;\n 1 4     p           19.9     22\n 2 4     r           20.8     55\n 3 4     d           32.3      3\n 4 4     c           24        1\n 5 5     r           20.5      4\n 6 6     p           16.8     17\n 7 6     r           16.1     60\n 8 6     e           11        1\n 9 6     d           17        1\n10 8     p           13.8     13\n11 8     r           12.7     49\n12 8     e            9.57     7\n13 8     d           14        1\n\n\nThe highest mean city mileage is for a cars with 4 cylinders with diesel fuel while the lowest is for cars with 8 cylinders and petrol fuel.\n\n\nSeparate means of city mileage for every separate level of cyl and fuel.\n\nmpg_modified %&gt;%\n  group_by(manufacturer) %&gt;%\n  summarize(average_cty = mean(cty))\n\n# A tibble: 15 × 2\n   manufacturer average_cty\n   &lt;chr&gt;              &lt;dbl&gt;\n 1 audi                17.6\n 2 chevrolet           15  \n 3 dodge               13.1\n 4 ford                14  \n 5 honda               24.4\n 6 hyundai             18.6\n 7 jeep                13.5\n 8 land rover          11.5\n 9 lincoln             11.3\n10 mercury             13.2\n11 nissan              18.1\n12 pontiac             17  \n13 subaru              19.3\n14 toyota              18.5\n15 volkswagen          20.9\n\n\nThe highest mean city mileage is for a cars with 4 cylinders with diesel fuel while the lowest is for electric cars with 6 cylinders."
  },
  {
    "objectID": "posts/Day-2/index.html#math-anxiety-data-set",
    "href": "posts/Day-2/index.html#math-anxiety-data-set",
    "title": "Day 2",
    "section": "Math Anxiety Data-Set:",
    "text": "Math Anxiety Data-Set:\n\nmath_anx &lt;- read_delim(\"../../data/MathAnxiety.csv\", delim=\";\")\n\nRows: 599 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (2): Gender, Grade\ndbl (3): AMAS, RCMAS, Arith\nnum (1): Age\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nmath_anx\n\n# A tibble: 599 × 6\n     Age Gender Grade      AMAS RCMAS Arith\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  1378 Boy    Secondary     9    20     6\n 2  1407 Boy    Secondary    18     8     6\n 3  1379 Girl   Secondary    23    26     5\n 4  1428 Girl   Secondary    19    18     7\n 5  1356 Boy    Secondary    23    20     1\n 6  1350 Girl   Secondary    27    33     1\n 7  1336 Boy    Secondary    22    23     4\n 8  1393 Boy    Secondary    17    11     7\n 9  1317 Girl   Secondary    28    32     2\n10  1348 Boy    Secondary    20    30     6\n# ℹ 589 more rows\n\n\n###Glimpse the data to understand which we have to change to factors.\n\nmath_anx %&gt;% dplyr::glimpse()\n\nRows: 599\nColumns: 6\n$ Age    &lt;dbl&gt; 1378, 1407, 1379, 1428, 1356, 1350, 1336, 1393, 1317, 1348, 141…\n$ Gender &lt;chr&gt; \"Boy\", \"Boy\", \"Girl\", \"Girl\", \"Boy\", \"Girl\", \"Boy\", \"Boy\", \"Gir…\n$ Grade  &lt;chr&gt; \"Secondary\", \"Secondary\", \"Secondary\", \"Secondary\", \"Secondary\"…\n$ AMAS   &lt;dbl&gt; 9, 18, 23, 19, 23, 27, 22, 17, 28, 20, 16, 20, 21, 36, 16, 27, …\n$ RCMAS  &lt;dbl&gt; 20, 8, 26, 18, 20, 33, 23, 11, 32, 30, 10, 4, 23, 26, 24, 21, 3…\n$ Arith  &lt;dbl&gt; 6, 6, 5, 7, 1, 1, 4, 7, 2, 6, 2, 5, 2, 6, 2, 7, 2, 4, 7, 3, 8, …\n\n\n\n\n\n\n\n\n\n\nVariable name\nDescription\nType of variable\n\n\n\n\nAge\nRepresents the age of the individual\nQualitative\n\n\nGender\nRepresents the gender of the individual(male/female)\nQualitative\n\n\nGrade\nRepresents the grade they study in\nQualitative\n\n\nAMAS\nAdult Manifest Anxiety Scale\nQuantitative\n\n\nRCMAS\nRevised Children’s Manifest Anxiety Scale\nQuantitative\n\n\nArith\nArithmetic Subtest of Intelligence Tests\nQuantitative\n\n\n\nTarget Variable: AMAS, RCMAS and Arith Predictor Variables: Age, Gender and Grade\n\nMutate to facors:\n\nAmong all variables, Gender, Grade and Arith must be turned into factors.\n\n\nmath_anx_modified &lt;- math_anx %&gt;%\n  dplyr::mutate(\n    Gender = as_factor(Gender),\n    Grade = as_factor(Grade),\n    Arith = as_factor(Arith)\n  )\nglimpse(math_anx_modified)\n\nRows: 599\nColumns: 6\n$ Age    &lt;dbl&gt; 1378, 1407, 1379, 1428, 1356, 1350, 1336, 1393, 1317, 1348, 141…\n$ Gender &lt;fct&gt; Boy, Boy, Girl, Girl, Boy, Girl, Boy, Boy, Girl, Boy, Boy, Boy,…\n$ Grade  &lt;fct&gt; Secondary, Secondary, Secondary, Secondary, Secondary, Secondar…\n$ AMAS   &lt;dbl&gt; 9, 18, 23, 19, 23, 27, 22, 17, 28, 20, 16, 20, 21, 36, 16, 27, …\n$ RCMAS  &lt;dbl&gt; 20, 8, 26, 18, 20, 33, 23, 11, 32, 30, 10, 4, 23, 26, 24, 21, 3…\n$ Arith  &lt;fct&gt; 6, 6, 5, 7, 1, 1, 4, 7, 2, 6, 2, 5, 2, 6, 2, 7, 2, 4, 7, 3, 8, …\n\n\n\n\nSummerising the data with skim:\n\nmath_anx_modified %&gt;% skimr::skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n599\n\n\nNumber of columns\n6\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n3\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nGender\n0\n1\nFALSE\n2\nBoy: 323, Gir: 276\n\n\nGrade\n0\n1\nFALSE\n2\nPri: 401, Sec: 198\n\n\nArith\n0\n1\nFALSE\n9\n7: 112, 6: 109, 8: 94, 5: 93\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nAge\n0\n1\n1246.49\n223.11\n37\n1061.5\n1208\n1418.5\n1875\n▁▁▇▇▃\n\n\nAMAS\n0\n1\n21.98\n6.60\n4\n18.0\n22\n26.5\n45\n▂▆▇▃▁\n\n\nRCMAS\n0\n1\n19.24\n7.57\n1\n14.0\n19\n25.0\n41\n▂▇▇▅▁\n\n\n\n\n\n\nAnxiety based on Gender:\n\nmath_anx_modified %&gt;%\n  group_by(Gender) %&gt;%\n  summarize(average_AMAS = mean(AMAS), average_RCMAS = mean(RCMAS), count =n())\n\n# A tibble: 2 × 4\n  Gender average_AMAS average_RCMAS count\n  &lt;fct&gt;         &lt;dbl&gt;         &lt;dbl&gt; &lt;int&gt;\n1 Boy            21.2          18.1   323\n2 Girl           22.9          20.6   276\n\n\nHypothesis to Evaluate: Girls have a higher anxiety level.\n\n\nAnxiety based on Grade:\n\nmath_anx_modified %&gt;%\n  group_by(Grade) %&gt;%\n  summarize(average_AMAS = mean(AMAS), average_RCMAS = mean(RCMAS), count =n())\n\n# A tibble: 2 × 4\n  Grade     average_AMAS average_RCMAS count\n  &lt;fct&gt;            &lt;dbl&gt;         &lt;dbl&gt; &lt;int&gt;\n1 Secondary         22.3          18.5   198\n2 Primary           21.8          19.6   401\n\n\nHypothesis to Evaluate: Primary school students experience more anxiety than secondary school students.\n\n\nAnxiety based on Grade and Gender:\n\nmath_anx_modified %&gt;%\n  group_by(Grade, Gender) %&gt;%\n  summarize(average_AMAS = mean(AMAS), average_RCMAS = mean(RCMAS), count =n())\n\n`summarise()` has grouped output by 'Grade'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 4 × 5\n# Groups:   Grade [2]\n  Grade     Gender average_AMAS average_RCMAS count\n  &lt;fct&gt;     &lt;fct&gt;         &lt;dbl&gt;         &lt;dbl&gt; &lt;int&gt;\n1 Secondary Boy            21.5          17.4   124\n2 Secondary Girl           23.5          20.3    74\n3 Primary   Boy            20.9          18.6   199\n4 Primary   Girl           22.7          20.6   202\n\n\nHypothesis to Evaluate: Girls studying in secondary school have the highest anxiety and Secondary School boys have the least amount of anxiety.\n\n\nAnxiety based on Arithmetic Subtest of Intelligence Tests:\n\nmath_anx_modified %&gt;%\n  group_by(Arith) %&gt;%\n  summarize(average_AMAS = mean(AMAS), average_RCMAS = mean(RCMAS), count =n())\n\n# A tibble: 9 × 4\n  Arith average_AMAS average_RCMAS count\n  &lt;fct&gt;        &lt;dbl&gt;         &lt;dbl&gt; &lt;int&gt;\n1 0             22.5          20.9    15\n2 1             24.5          23.9    25\n3 2             23.6          21.0    26\n4 3             24.2          18.2    56\n5 4             21.7          19.3    69\n6 5             21.2          19.7    93\n7 6             22.5          19.4   109\n8 7             21.4          18.1   112\n9 8             20.5          18.5    94\n\n\nI don’t really know how to read this last data."
  },
  {
    "objectID": "posts/day-4/index.html",
    "href": "posts/day-4/index.html",
    "title": "Day 4",
    "section": "",
    "text": "Quant and Qual Variable Graphs and their Siblings (god knows what that means).\nA histogram is a graphical representation of the distribution of continuous numerical data, where data is grouped into ranges (or bins), and the frequency of data points in each bin is displayed using bars. Quant variables will be present on the x-axis and the histogram shows us how frequently different values occur for that variable by showing counts/frequencies on the y-axis. we use “gf_histogram” for this.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula)\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\n##\nlibrary(crosstable)\n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact"
  },
  {
    "objectID": "posts/day-4/index.html#introduction",
    "href": "posts/day-4/index.html#introduction",
    "title": "Day 4",
    "section": "",
    "text": "Quant and Qual Variable Graphs and their Siblings (god knows what that means).\nA histogram is a graphical representation of the distribution of continuous numerical data, where data is grouped into ranges (or bins), and the frequency of data points in each bin is displayed using bars. Quant variables will be present on the x-axis and the histogram shows us how frequently different values occur for that variable by showing counts/frequencies on the y-axis. we use “gf_histogram” for this.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula)\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\n##\nlibrary(crosstable)\n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact"
  },
  {
    "objectID": "posts/day-4/index.html#diamonds-data-set",
    "href": "posts/day-4/index.html#diamonds-data-set",
    "title": "Day 4",
    "section": "Diamonds data-set:",
    "text": "Diamonds data-set:\n\ndiamonds\n\n# A tibble: 53,940 × 10\n   carat cut       color clarity depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n 7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n 8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n 9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n# ℹ 53,930 more rows\n\n\n\nglimpse(diamonds)\n\nRows: 53,940\nColumns: 10\n$ carat   &lt;dbl&gt; 0.23, 0.21, 0.23, 0.29, 0.31, 0.24, 0.24, 0.26, 0.22, 0.23, 0.…\n$ cut     &lt;ord&gt; Ideal, Premium, Good, Premium, Good, Very Good, Very Good, Ver…\n$ color   &lt;ord&gt; E, E, E, I, J, J, I, H, E, H, J, J, F, J, E, E, I, J, J, J, I,…\n$ clarity &lt;ord&gt; SI2, SI1, VS1, VS2, SI2, VVS2, VVS1, SI1, VS2, VS1, SI1, VS1, …\n$ depth   &lt;dbl&gt; 61.5, 59.8, 56.9, 62.4, 63.3, 62.8, 62.3, 61.9, 65.1, 59.4, 64…\n$ table   &lt;dbl&gt; 55, 61, 65, 58, 58, 57, 57, 55, 61, 61, 55, 56, 61, 54, 62, 58…\n$ price   &lt;int&gt; 326, 326, 327, 334, 335, 336, 336, 337, 337, 338, 339, 340, 34…\n$ x       &lt;dbl&gt; 3.95, 3.89, 4.05, 4.20, 4.34, 3.94, 3.95, 4.07, 3.87, 4.00, 4.…\n$ y       &lt;dbl&gt; 3.98, 3.84, 4.07, 4.23, 4.35, 3.96, 3.98, 4.11, 3.78, 4.05, 4.…\n$ z       &lt;dbl&gt; 2.43, 2.31, 2.31, 2.63, 2.75, 2.48, 2.47, 2.53, 2.49, 2.39, 2.…\n\n\n\nConsidering the fact that all qualitative data is already ordered and factored, we don’t mutate any values here.\n\n\nskim(diamonds)\n\n\nData summary\n\n\nName\ndiamonds\n\n\nNumber of rows\n53940\n\n\nNumber of columns\n10\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n3\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\ncut\n0\n1\nTRUE\n5\nIde: 21551, Pre: 13791, Ver: 12082, Goo: 4906\n\n\ncolor\n0\n1\nTRUE\n7\nG: 11292, E: 9797, F: 9542, H: 8304\n\n\nclarity\n0\n1\nTRUE\n8\nSI1: 13065, VS2: 12258, SI2: 9194, VS1: 8171\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ncarat\n0\n1\n0.80\n0.47\n0.2\n0.40\n0.70\n1.04\n5.01\n▇▂▁▁▁\n\n\ndepth\n0\n1\n61.75\n1.43\n43.0\n61.00\n61.80\n62.50\n79.00\n▁▁▇▁▁\n\n\ntable\n0\n1\n57.46\n2.23\n43.0\n56.00\n57.00\n59.00\n95.00\n▁▇▁▁▁\n\n\nprice\n0\n1\n3932.80\n3989.44\n326.0\n950.00\n2401.00\n5324.25\n18823.00\n▇▂▁▁▁\n\n\nx\n0\n1\n5.73\n1.12\n0.0\n4.71\n5.70\n6.54\n10.74\n▁▁▇▃▁\n\n\ny\n0\n1\n5.73\n1.14\n0.0\n4.72\n5.71\n6.54\n58.90\n▇▁▁▁▁\n\n\nz\n0\n1\n3.54\n0.71\n0.0\n2.91\n3.53\n4.04\n31.80\n▇▁▁▁▁\n\n\n\n\n\n\n\ncarat: weight of the diamond 0.2-5.01\ndepth: depth total depth percentage 43-79\ntable: width of top of diamond relative to widest point 43-95\nprice: price in US dollars $326-$18,823\nx: length in mm 0-10.74\ny: width in mm 0-58.9\nz(dbl): depth in mm 0-31.8\n\n\n\nThere are no missing values for any variable, all are complete with 54K entries.\n\n\nMy first histogram!!!!\n\nPlotting diamond prices.\n\n## if i want i can not specigy the bins too. \ngf_histogram(~price,\n  data = diamonds,\n  bins = 100\n) %&gt;%\n  gf_labs(\n    title = \"Plot 1A: Diamond Prices\",\n    caption = \"ggformula\"\n  )\n\n\n\n\n\n\n\n\nWe can infer that while a large number of diamonds are priced relatively low, there are also a significant number of diamonds that are priced very high.\n\n\nWhat is the distribution of the predictor variable carat?\n\ndiamonds %&gt;%\n  gf_histogram(~carat,\n    bins = 100\n  ) %&gt;%\n  gf_labs(\n    title = \"Plot 2B: Carats of Diamonds\",\n    caption = \"ggformula\"\n  )\n\n\n\n\n\n\n\n\nWe can infer that there must be some, very few, diamonds of very high carat value while there a few carat values that appear to be more than common! People very commonly buy diamonds of 1 carat and a little less frequently 0.5, 1.5 and 2.\n\n\nDoes a price distribution vary based upon type of cut?\n\nfrom what i observe, the fill acts as a stack here, although it is prices that are represented in the historgram, we able to observe what portion of each bin is occupied by each of the cuts\n\n\ngf_histogram(~price, fill = ~cut, data = diamonds, bins=100) %&gt;%\n  gf_labs(title = \"Plot 3A: Diamond Prices\", caption = \"ggformula\")\n\n\n\n\n\n\n\n\n\ndiamonds %&gt;%\n  gf_histogram(~price|cut, fill = ~cut, color = \"black\", alpha = 0.3) %&gt;%\n  gf_labs(\n    title = \"Plot 3C: Prices by Filled and Facetted by Cut\",\n    caption = \"ggformula\"\n  ) %&gt;%\n  gf_theme(theme(\n    axis.text.x = element_text(\n      angle = 45, ## the angle at which the word should be placed.\n      hjust = 1 ## the incremanting space from the x axis\n    )\n  ))\n\n\n\n\n\n\n\n\nusing this, we can observe the price range of each individual cut as different graphs, but very low values (in comparison to high values of ideal) such as those in fair and good. We can make them have ranges of values in y axis based on their individual values by setting scales to be free y.\n\n## the nrow, defines the number of rows \ndiamonds %&gt;%\n  gf_histogram(~price, fill = ~cut, color = \"black\", alpha = 0.3) %&gt;%\n  gf_facet_wrap(~cut, scales = \"free_y\", nrow = 2) %&gt;%\n  gf_labs(\n    title = \"Plot 3D: Prices Filled and Facetted by Cut\",\n    subtitle = \"Free y-scale\",\n    caption = \"ggformula\"\n  ) %&gt;%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n\n\n\n\n\n\n\n\nPrice ranges are the same regardless of cut and so that must not be the only parameter in dermeining the price\n\n\nDoes a price distribution vary based upon type of clarity?\n\ngf_histogram(~price, fill = ~clarity, data = diamonds) %&gt;%\n  gf_labs(title = \"Plot 3A: Diamond Prices spereated by clarity\")\n\n\n\n\n\n\n\n\n\ndiamonds %&gt;%\n  gf_histogram(~price, fill = ~clarity, color = \"black\", alpha = 0.3) %&gt;%\n  gf_facet_wrap(~clarity) %&gt;%\n  gf_labs(\n    title = \"Plot 4A: Prices Filled and Facetted by Clarity\",\n    subtitle = \"Free y-scale\",\n    caption = \"ggformula\"\n  ) %&gt;%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n\n\n\n\n\n\n\n\n\n## the nrow, defines the number of rows \ndiamonds %&gt;%\n  gf_histogram(~price, fill = ~clarity, color = \"black\", alpha = 0.3) %&gt;%\n  gf_facet_wrap(~clarity, scales = \"free_y\", nrow = 2) %&gt;%\n  gf_labs(\n    title = \"Plot 4A: Prices Filled and Facetted by Clarity\",\n    subtitle = \"Free y-scale\",\n    caption = \"ggformula\"\n  ) %&gt;%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n\n\n\n\n\n\n\n\nPrice ranges are the same regardless of clarity and so that must not be the only parameter in determining the price but SI1 appease to have the most in high prices\n\n\nDoes a price distribution vary based upon type of colour?\n\ngf_histogram(~price, fill = ~color, data = diamonds) %&gt;%\n  gf_labs(title = \"Plot: Diamond Prices spereated by color\")\n\n\n\n\n\n\n\n\n\ndiamonds %&gt;%\n  gf_histogram(~price, fill = ~color, color = \"black\", alpha = 0.3) %&gt;%\n  gf_facet_wrap(~color) %&gt;%\n  gf_labs(\n    title = \"Plot: Prices Filled and Facetted by Color\",\n    subtitle = \"Free y-scale\",\n  ) %&gt;%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n\n\n\n\n\n\n\n\n\ndiamonds %&gt;%\n  gf_histogram(~price, fill = ~color, color = \"black\", alpha = 0.3) %&gt;%\n  gf_facet_wrap(~color, scales = \"free_y\", nrow = 2) %&gt;%\n  gf_labs(\n    title = \"Plot: Prices Filled and Facetted by Color\",\n    subtitle = \"Free y-scale\",\n  ) %&gt;%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))"
  },
  {
    "objectID": "posts/day-4/index.html#the-race-data-set",
    "href": "posts/day-4/index.html#the-race-data-set",
    "title": "Day 4",
    "section": "The Race data-set",
    "text": "The Race data-set\n\nrace_df &lt;- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-26/race.csv\")\n\nRows: 1207 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (5): event, race, city, country, participation\ndbl  (6): race_year_id, distance, elevation_gain, elevation_loss, aid_statio...\ndate (1): date\ntime (1): start_time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nrace_df\n\n# A tibble: 1,207 × 13\n   race_year_id event    race  city  country date       start_time participation\n          &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;date&gt;     &lt;time&gt;     &lt;chr&gt;        \n 1        68140 Peak Di… Mill… Cast… United… 2021-09-03 19:00      solo         \n 2        72496 UTMB®    UTMB® Cham… France  2021-08-27 17:00      Solo         \n 3        69855 Grand R… Ultr… viel… France  2021-08-20 05:00      solo         \n 4        67856 Persenk… PERS… Asen… Bulgar… 2021-08-20 18:00      solo         \n 5        70469 Runfire… 100 … uluk… Turkey  2021-08-20 18:00      solo         \n 6        66887 Swiss A… 160KM Müns… Switze… 2021-08-15 17:00      solo         \n 7        67851 Salomon… Salo… Foll… Norway  2021-08-14 07:00      solo         \n 8        68241 Ultra T… 160KM Spa   Belgium 2021-08-14 07:00      solo         \n 9        70241 Québec … QMT-… Beau… Canada  2021-08-13 22:00      solo         \n10        69945 Bunketo… BBUT… LIND… Sweden  2021-08-07 10:00      solo         \n# ℹ 1,197 more rows\n# ℹ 5 more variables: distance &lt;dbl&gt;, elevation_gain &lt;dbl&gt;,\n#   elevation_loss &lt;dbl&gt;, aid_stations &lt;dbl&gt;, participants &lt;dbl&gt;\n\nrank_df &lt;- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-26/ultra_rankings.csv\")\n\nRows: 137803 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): runner, time, gender, nationality\ndbl (4): race_year_id, rank, age, time_in_seconds\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nrank_df\n\n# A tibble: 137,803 × 8\n   race_year_id  rank runner      time    age gender nationality time_in_seconds\n          &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;                 &lt;dbl&gt;\n 1        68140     1 VERHEUL Ja… 26H …    30 M      GBR                   95725\n 2        68140     2 MOULDING J… 27H …    43 M      GBR                   97229\n 3        68140     3 RICHARDSON… 28H …    38 M      GBR                  103747\n 4        68140     4 DYSON Fiona 30H …    55 W      GBR                  111217\n 5        68140     5 FRONTERAS … 32H …    48 W      GBR                  117981\n 6        68140     6 THOMAS Lei… 32H …    31 M      GBR                  118000\n 7        68140     7 SHORT Debo… 33H …    55 W      GBR                  120601\n 8        68140     8 CROSSLEY C… 33H …    40 W      GBR                  120803\n 9        68140     9 BUTCHER Ke… 34H …    47 M      GBR                  125656\n10        68140    10 Hendry Bill 34H …    29 M      GBR                  125979\n# ℹ 137,793 more rows\n\n\n\nglimpse(race_df)\n\nRows: 1,207\nColumns: 13\n$ race_year_id   &lt;dbl&gt; 68140, 72496, 69855, 67856, 70469, 66887, 67851, 68241,…\n$ event          &lt;chr&gt; \"Peak District Ultras\", \"UTMB®\", \"Grand Raid des Pyréné…\n$ race           &lt;chr&gt; \"Millstone 100\", \"UTMB®\", \"Ultra Tour 160\", \"PERSENK UL…\n$ city           &lt;chr&gt; \"Castleton\", \"Chamonix\", \"vielle-Aure\", \"Asenovgrad\", \"…\n$ country        &lt;chr&gt; \"United Kingdom\", \"France\", \"France\", \"Bulgaria\", \"Turk…\n$ date           &lt;date&gt; 2021-09-03, 2021-08-27, 2021-08-20, 2021-08-20, 2021-0…\n$ start_time     &lt;time&gt; 19:00:00, 17:00:00, 05:00:00, 18:00:00, 18:00:00, 17:0…\n$ participation  &lt;chr&gt; \"solo\", \"Solo\", \"solo\", \"solo\", \"solo\", \"solo\", \"solo\",…\n$ distance       &lt;dbl&gt; 166.9, 170.7, 167.0, 164.0, 159.9, 159.9, 163.8, 163.9,…\n$ elevation_gain &lt;dbl&gt; 4520, 9930, 9980, 7490, 100, 9850, 5460, 4630, 6410, 31…\n$ elevation_loss &lt;dbl&gt; -4520, -9930, -9980, -7500, -100, -9850, -5460, -4660, …\n$ aid_stations   &lt;dbl&gt; 10, 11, 13, 13, 12, 15, 5, 8, 13, 23, 13, 5, 12, 15, 0,…\n$ participants   &lt;dbl&gt; 150, 2300, 600, 150, 0, 300, 0, 200, 120, 100, 300, 50,…\n\n\n\nglimpse(rank_df)\n\nRows: 137,803\nColumns: 8\n$ race_year_id    &lt;dbl&gt; 68140, 68140, 68140, 68140, 68140, 68140, 68140, 68140…\n$ rank            &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, NA, NA, NA,…\n$ runner          &lt;chr&gt; \"VERHEUL Jasper\", \"MOULDING JON\", \"RICHARDSON Phill\", …\n$ time            &lt;chr&gt; \"26H 35M 25S\", \"27H 0M 29S\", \"28H 49M 7S\", \"30H 53M 37…\n$ age             &lt;dbl&gt; 30, 43, 38, 55, 48, 31, 55, 40, 47, 29, 48, 47, 52, 49…\n$ gender          &lt;chr&gt; \"M\", \"M\", \"M\", \"W\", \"W\", \"M\", \"W\", \"W\", \"M\", \"M\", \"M\",…\n$ nationality     &lt;chr&gt; \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\"…\n$ time_in_seconds &lt;dbl&gt; 95725, 97229, 103747, 111217, 117981, 118000, 120601, …\n\n\n\nmosaic::favstats returns a data frame with several common summary statistics, such as:\n\nmin: Minimum value\nQ1: First quartile (25th percentile)\nmedian: Median (50th percentile)\nQ3: Third quartile (75th percentile)\nmax: Maximum value\nmean: Arithmetic mean\nsd: Standard deviation\nn: Number of non-missing observations\nmissing: Number of missing values\nIQR: Interquartile range (Q3 - Q1)\n\n\n\nrace_df %&gt;%\n  favstats(~distance, data = .)\n\n min    Q1 median     Q3   max     mean       sd    n missing\n   0 160.1  161.5 165.15 179.1 152.6187 39.87864 1207       0\n\n\n\nrace_df %&gt;%\n  favstats(~participants, data = .)\n\n min Q1 median  Q3  max     mean       sd    n missing\n   0  0     21 150 2900 120.4872 281.8337 1207       0\n\n\n\nrank_df %&gt;%\n  drop_na() %&gt;%\n  favstats(time_in_seconds ~ gender, data = .)\n\n  gender  min      Q1 median       Q3    max     mean       sd      n missing\n1      M 3600 96536.5 115845 149761.5 288000 123271.1 37615.42 101643       0\n2      W 9191 96695.0 107062 131464.0 296806 117296.5 34604.26  18341       0\n\n\n\nOn occasion we may need to see summaries of several Quant variables, over levels of Qual variables. This is where the package crosstable is so effective. Therefore, crosstable is useful when you need to generate summary statistics of quantitative (numeric) variables, broken down by levels of qualitative (categorical) variables.\n\n\ncrosstable(time_in_seconds + age ~ gender, data = rank_df) %&gt;%\n  crosstable::as_flextable()\n\nlabelvariablegenderMWNAtime_in_secondsMin / Max3600.0 / 2.9e+059191.0 / 3.0e+058131.0 / 2.2e+05Med [IQR]1.2e+05 [9.7e+04;1.5e+05]1.1e+05 [9.7e+04;1.3e+05]1.2e+05 [9.9e+04;1.5e+05]Mean (std)1.2e+05 (3.8e+04)1.2e+05 (3.5e+04)1.2e+05 (4.4e+04)N (NA)101643 (15073)18341 (2716)28 (2)ageMin / Max0 / 133.00 / 81.029.0 / 59.0Med [IQR]47.0 [40.0;53.0]45.0 [39.0;52.0]40.5 [36.0;50.5]Mean (std)46.4 (10.2)45.3 (9.7)41.7 (9.0)N (NA)116716 (0)21057 (0)30 (0)\n\n\nMen participating are generally older than women. When it comes to time in seconds, while the overall central tendency (mean) remains consistent, the distribution of the data has some variation as shown by (std) and (median) but not the average - it’s the same.\n\nWhich countries host the maximum number of races? Which countries send the maximum number of participants??\n\nrace_df %&gt;%\n  count(country) %&gt;%\n  arrange(desc(n))\n\n# A tibble: 61 × 2\n   country            n\n   &lt;chr&gt;          &lt;int&gt;\n 1 United States    438\n 2 United Kingdom   110\n 3 France            56\n 4 Australia         46\n 5 Sweden            46\n 6 China             45\n 7 Canada            32\n 8 Spain             27\n 9 Japan             24\n10 Poland            23\n# ℹ 51 more rows\n\n\n\nrank_df %&gt;%\n  count(nationality) %&gt;%\n  arrange(desc(n))\n\n# A tibble: 133 × 2\n   nationality     n\n   &lt;chr&gt;       &lt;int&gt;\n 1 USA         47259\n 2 FRA         28905\n 3 GBR         11076\n 4 JPN          6729\n 5 ESP          5478\n 6 CHN          4744\n 7 CAN          2822\n 8 ITA          2794\n 9 SWE          2293\n10 AUS          1683\n# ℹ 123 more rows\n\n\nThe United states hosts the most number of games and send the most number of players.\n\n\nWhich country wins the most?\n\nrank_df %&gt;%\n  filter(rank %in% c(1, 2, 3)) %&gt;%\n  count(nationality) %&gt;%\n  arrange(desc(n))\n\n# A tibble: 69 × 2\n   nationality     n\n   &lt;chr&gt;       &lt;int&gt;\n 1 USA          1240\n 2 GBR           347\n 3 FRA           210\n 4 AUS           140\n 5 CAN           132\n 6 CHN           128\n 7 SWE           124\n 8 ESP           113\n 9 JPN            94\n10 ITA            79\n# ℹ 59 more rows\n\n\nTo no surprise, United states wins the most too. Would it be the same case if compared the ratio of players to wins?\n\n\nAnalyze the nationality of the top 10 participants in the longest races\n\n\nslice() allows you to select, remove, and duplicate rows. slice_min() and slice_max() select rows with the smallest or largest values of a variable.\nThe filter() function is used to subset a data frame, retaining all rows that satisfy your conditions.\nleft_join() is a function from the dplyr package used to combine two data frames by joining them based on a common column (or columns).\n\n\n\nlongest_races &lt;- race_df %&gt;%\n  slice_max(n = 5, order_by = distance) # Longest distance races\nlongest_races\n\n# A tibble: 6 × 13\n  race_year_id event     race  city  country date       start_time participation\n         &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;date&gt;     &lt;time&gt;     &lt;chr&gt;        \n1        68776 Ultra To… Ut4M… Gren… France  2021-07-16 18:00      Solo         \n2        55551 Ultra Tr… Inth… Chom… Thaila… 2020-02-14 10:00      solo         \n3         7484 Le TREG®… LE T… Fada  Chad    2015-02-06 00:00      solo         \n4         7594 THE GREA… 100 … Pato… Austra… 2014-09-13 00:00      Solo         \n5        71066 ULTRA 01  Ultr… Oyon… France  2021-07-09 18:00      solo         \n6        23565 EstrelAç… Estr… Penh… Portug… 2017-10-06 18:00      Solo         \n# ℹ 5 more variables: distance &lt;dbl&gt;, elevation_gain &lt;dbl&gt;,\n#   elevation_loss &lt;dbl&gt;, aid_stations &lt;dbl&gt;, participants &lt;dbl&gt;\n\nlongest_races %&gt;%\n  left_join(., rank_df, by = \"race_year_id\") %&gt;% # total participants in longest 4 races\n  filter(rank %in% c(1:10)) %&gt;% # Top 10 ranks\n  count(nationality) %&gt;%\n  arrange(desc(n))\n\n# A tibble: 9 × 2\n  nationality     n\n  &lt;chr&gt;       &lt;int&gt;\n1 FRA            26\n2 AUS             9\n3 POR             8\n4 THA             8\n5 BEL             1\n6 BRA             1\n7 ESP             1\n8 MAS             1\n9 RUS             1\n\n\n\nWe get 2 tables - one with the joined data set, the other with the nationality and count of the amount of wins (top 10 rank among the longest races).\n\nThese quantities show that even though USA has the most number of wins, for the longest races, france has the most participents among everyone the top 10 rank.\n\n\nWhat is the distribution of the finishing times?\n\nrank_df %&gt;%\n  gf_histogram(~time_in_seconds, bins = 75) %&gt;%\n  gf_labs(title = \"Histogram of Race Times\")\n\nWarning: Removed 17791 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\nMost people finished the race at 1e+05. The histogram shows three bumps (is this a result of the difference in distance?)\n\n\nWhat is the distribution of race distances?\n\nrace_df %&gt;%\n  gf_histogram(~distance, bins = 50) %&gt;%\n  gf_labs(title = \"Histogram of Race Distances\")\n\n\n\n\n\n\n\n\nHow are there multiple races at 0 distance, is this a glitch in the data? There are very few races between 0-150. Most races seem to be set at a distance from 150 -180.\n\nrace_df %&gt;%\n  filter(distance == 0)\n\n# A tibble: 74 × 13\n   race_year_id event    race  city  country date       start_time participation\n          &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;date&gt;     &lt;time&gt;     &lt;chr&gt;        \n 1        64771 The Old… 100m… Hanm… New Ze… 2021-05-14 10:00      solo         \n 2        71220 Run Lov… 100M  &lt;NA&gt;  United… 2021-02-26 00:00      solo         \n 3        67160 IDAHO M… 100 … &lt;NA&gt;  United… 2020-09-12 00:00      solo         \n 4        67713 Pine cr… 100M… Well… PA, Un… 2020-09-12 00:00      solo         \n 5        51777 Chiemga… 100 … Berg… Germany 2020-07-31 13:00      Solo         \n 6        66413 Palisad… Moos… Irwin United… 2020-07-17 05:00      solo         \n 7        62593 Run Lov… 100M  &lt;NA&gt;  United… 2020-02-28 00:00      solo         \n 8        50097 The Gre… The … Hanm… New Ze… 2020-01-17 07:00      solo         \n 9        65861 Loup Ga… 100M  Vill… LA, Un… 2019-12-14 00:00      solo         \n10        59415 RIO DEL… 100 … &lt;NA&gt;  United… 2019-11-07 00:00      solo         \n# ℹ 64 more rows\n# ℹ 5 more variables: distance &lt;dbl&gt;, elevation_gain &lt;dbl&gt;,\n#   elevation_loss &lt;dbl&gt;, aid_stations &lt;dbl&gt;, participants &lt;dbl&gt;\n\n\nEven though there are so many races registerd as 100 mile races, non of the distances are 100 in the histogram.\n\n\nWhat is the distribution of finishing times for race distance around 150 faceted by time of day?\nA count of start times:\n\nrace_times &lt;- race_df %&gt;%\n  count(start_time) %&gt;%\n  arrange(desc(n))\nrace_times\n\n# A tibble: 39 × 2\n   start_time     n\n   &lt;time&gt;     &lt;int&gt;\n 1 00:00        513\n 2 06:00        114\n 3 08:00         63\n 4 10:00         60\n 5 07:00         58\n 6 18:00         50\n 7 05:00         48\n 8 12:00         38\n 9 04:00         30\n10 09:00         27\n# ℹ 29 more rows\n\n\nWe section a day into different groups of time: example morning, noon, evening and create a new column start_day_time with this information; since might and post midnight can be categorized as the same, we use fact_collapse to combine it to be the same. left_join() is used to merge race_start_factor with another data frame rank_df based on the race_year_id column, which is common between both. drop_na() removes any rows where time_in_seconds is NA (i.e., missing values). This ensures the plot only uses races with valid time data. hms- hour minute second.\n\nrace_start_factor &lt;- race_df %&gt;%\n  filter(distance == 0) %&gt;% # Races that actually took place\n  mutate(\n    ## start day time is a new column you are creating based on the values in\n    start_day_time =\n      case_when(\n        start_time &gt; hms(\"02:00:00\") &\n          start_time &lt;= hms(\"06:00:00\") ~ \"early_morning\",\n        start_time &gt; hms(\"06:00:01\") &\n          start_time &lt;= hms(\"10:00:00\") ~ \"late_morning\",\n        start_time &gt; hms(\"10:00:01\") &\n          start_time &lt;= hms(\"14:00:00\") ~ \"mid_day\",\n        start_time &gt; hms(\"14:00:01\") &\n          start_time &lt;= hms(\"18:00:00\") ~ \"afternoon\",\n        start_time &gt; hms(\"18:00:01\") &\n          start_time &lt;= hms(\"22:00:00\") ~ \"evening\",\n        start_time &gt; hms(\"22:00:01\") &\n          start_time &lt;= hms(\"23:59:59\") ~ \"night\",\n        start_time &gt;= hms(\"00:00:00\") &\n          start_time &lt;= hms(\"02:00:00\") ~ \"postmidnight\",\n        .default = \"other\"\n      )\n  ) %&gt;%\n  mutate(\n    start_day_time =\n      as_factor(start_day_time) %&gt;%\n        fct_collapse(\n          .f = .,\n          night = c(\"night\", \"postmidnight\")\n        )\n  )\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `start_day_time = `%&gt;%`(...)`.\nCaused by warning:\n! Unknown levels in `f`: night\n\n##\n# Join with rank_df\nrace_start_factor %&gt;%\n  left_join(rank_df, by = \"race_year_id\") %&gt;%\n  drop_na(time_in_seconds) %&gt;%\n  gf_histogram(\n    ~time_in_seconds,\n    bins = 75,\n    fill = ~start_day_time,\n    color = ~start_day_time,\n    alpha = 0.5\n  ) %&gt;%\n  gf_facet_wrap(vars(start_day_time), ncol = 2, scales = \"free_y\") %&gt;%\n  gf_labs(title = \"Race Times by Start-Time\")\n\n\n\n\n\n\n\n\nWe see that finish times tend to be longer for afternoon and evening start races"
  },
  {
    "objectID": "posts/day-4/index.html#populations-data-set",
    "href": "posts/day-4/index.html#populations-data-set",
    "title": "Day 4",
    "section": "Populations data-set",
    "text": "Populations data-set\n\npop &lt;- read_delim(\"../../data/populations.csv\")\n\nRows: 16400 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): country_code, country_name\ndbl (2): year, value\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npop\n\n# A tibble: 16,400 × 4\n   country_code country_name  year value\n   &lt;chr&gt;        &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n 1 ABW          Aruba         1960 54608\n 2 ABW          Aruba         1961 55811\n 3 ABW          Aruba         1962 56682\n 4 ABW          Aruba         1963 57475\n 5 ABW          Aruba         1964 58178\n 6 ABW          Aruba         1965 58782\n 7 ABW          Aruba         1966 59291\n 8 ABW          Aruba         1967 59522\n 9 ABW          Aruba         1968 59471\n10 ABW          Aruba         1969 59330\n# ℹ 16,390 more rows\n\ninspect(pop)\n\n\ncategorical variables:  \n          name     class levels     n missing\n1 country_code character    265 16400       0\n2 country_name character    265 16400       0\n                                   distribution\n1 ABW (0.4%), AFE (0.4%), AFG (0.4%) ...       \n2 Afghanistan (0.4%) ...                       \n\nquantitative variables:  \n   name   class  min       Q1  median       Q3        max         mean\n1  year numeric 1960   1975.0    1991     2006       2021 1.990529e+03\n2 value numeric 2646 986302.5 6731400 46024452 7888408686 2.140804e+08\n            sd     n missing\n1 1.789551e+01 16400       0\n2 7.040554e+08 16400       0\n\n\nThere are many countries with small populations and a few countries with very large populations. Such distributions are also called “long tailed” distributions.\n\ngf_histogram(~value, data = pop, title = \"Long Tailed Histogram\")\n\n\n\n\n\n\n\n##\ngf_density(~value, data = pop, title = \"Long Tailed Density\")\n\n\n\n\n\n\n\n\nTo develop better insights with this data, we should transform the variable concerned, using say a “log” transformation:\n\ngf_histogram(~ log10(value), data = pop, title = \"Histogram with Log transformed x-variable\")\n\n\n\n\n\n\n\n##\ngf_density(~ log10(value), data = pop, title = \"Density with Log transformed x-variable\")"
  },
  {
    "objectID": "posts/day-4/index.html#what-does-each-distribution-signify",
    "href": "posts/day-4/index.html#what-does-each-distribution-signify",
    "title": "Day 4",
    "section": "What does each distribution signify?",
    "text": "What does each distribution signify?\n\n\n\nBimodal: There could be two different underlying processes or populations contributing to the data.\nComb: The data might have been processed in a way that grouped values together in regular intervals.A comb distribution could appear in data where ages are rounded to the nearest five years (e.g., 20, 25, 30).\nEdge Peak: Could even be a data entry artifact!! All unknown / unrecorded observations are recorded as 999 !!🙀\nNormal: The data follows a typical pattern where most values are close to the mean, and extremes are rare. This distribution occurs frequently in nature and in many datasets due to the Central Limit Theorem.\nSkewed: Right skew suggests that most values are clustered at the lower end, but there are some extreme high values. Left skew suggests that most values are clustered at the higher end, but there are some extreme low values.\nUniform: This can suggest random or non-preferential selection of values."
  },
  {
    "objectID": "posts/Workflow/index.html",
    "href": "posts/Workflow/index.html",
    "title": " Facing the Abyss - WorkFLow",
    "section": "",
    "text": "So you have your shiny new R skills and you’ve successfully loaded a cool dataframe into R… Now what?\nThe best charts come from understanding your data, asking good questions from it, and displaying the answers to those questions as clearly as possible."
  },
  {
    "objectID": "posts/Workflow/index.html#a-data-analytics-process",
    "href": "posts/Workflow/index.html#a-data-analytics-process",
    "title": " Facing the Abyss - WorkFLow",
    "section": "",
    "text": "So you have your shiny new R skills and you’ve successfully loaded a cool dataframe into R… Now what?\nThe best charts come from understanding your data, asking good questions from it, and displaying the answers to those questions as clearly as possible."
  },
  {
    "objectID": "posts/Workflow/index.html#setting-up-r-packages",
    "href": "posts/Workflow/index.html#setting-up-r-packages",
    "title": " Facing the Abyss - WorkFLow",
    "section": "{{< iconify noto-v1 package >}} Setting up R Packages",
    "text": "{{&lt; iconify noto-v1 package &gt;}} Setting up R Packages\n\nInstall packages using install.packages() in your Console.\nLoad up your libraries in a setup chunk:\n\n\nknitr::opts_chunk$set(dev = \"ragg_png\")\n\nlibrary(tidyverse)\nlibrary(mosaic)\nlibrary(palmerpenguins)\nlibrary(ggformula)\nlibrary(ggridges)\nlibrary(skimr)\n##\nlibrary(GGally)\nlibrary(corrplot)\nlibrary(corrgram)\n\nGo to https://fonts.google.com/ and choose some professional looking, or funky looking, fonts.\n\nlibrary(extrafont)\n\nRegistering fonts with R\n\nextrafont::loadfonts(quiet = TRUE)\n##\nlibrary(showtext)\n\nLoading required package: sysfonts\n\n\nLoading required package: showtextdb\n\n\n\nAttaching package: 'showtextdb'\n\n\nThe following object is masked from 'package:extrafont':\n\n    font_install\n\n## Loading Google fonts (https://fonts.google.com/)\nfont_add_google(name = \"Fira Sans Condensed\", family = \"fira\")\nfont_add_google(\"Gochi Hand\", \"gochi\")\nfont_add_google(\"Schoolbell\", \"bell\")\nfont_add_google(\"Montserrat Alternates\", \"montserrat\")\nfont_add_google(\"Roboto Condensed\", \"roboto\")\n### Automatically use showtext to render text\nshowtext_auto()"
  },
  {
    "objectID": "posts/Workflow/index.html#read-data",
    "href": "posts/Workflow/index.html#read-data",
    "title": " Facing the Abyss - WorkFLow",
    "section": "Read Data",
    "text": "Read Data\n\nUse readr::read_csv()"
  },
  {
    "objectID": "posts/Workflow/index.html#examine-data",
    "href": "posts/Workflow/index.html#examine-data",
    "title": " Facing the Abyss - WorkFLow",
    "section": "Examine Data",
    "text": "Examine Data\n\nUse dplyr::glimpse()\nUse mosaic::inspect() or skimr::skim()\nUse dplyr::summarise() and crosstable::crosstable()\nFormat your tables with knitr::kable()\nHighlight any interesting summary stats or data imbalances"
  },
  {
    "objectID": "posts/Workflow/index.html#data-dictionary-and-experiment-description",
    "href": "posts/Workflow/index.html#data-dictionary-and-experiment-description",
    "title": " Facing the Abyss - WorkFLow",
    "section": "Data Dictionary and Experiment Description",
    "text": "Data Dictionary and Experiment Description\n\nA table containing the variable names, their interpretation, and their nature(Qual/Quant/Ord…)\nIf there are wrongly coded variables in the original data, state them in their correct form, so you can munge the in the next step\nDeclare what might be target and predictor variables, based on available information of the experiment, or a description of the data"
  },
  {
    "objectID": "posts/Workflow/index.html#data-munging",
    "href": "posts/Workflow/index.html#data-munging",
    "title": " Facing the Abyss - WorkFLow",
    "section": "Data Munging",
    "text": "Data Munging\n\nConvert variables to factors as needed\nReformat / Rename other variables as needed\nClean badly formatted columns (e.g. text + numbers) using tidyr::separate_**_**()\nSave the data as a modified file\nDo not mess up the original data file"
  },
  {
    "objectID": "posts/Workflow/index.html#form-hypotheses",
    "href": "posts/Workflow/index.html#form-hypotheses",
    "title": " Facing the Abyss - WorkFLow",
    "section": "Form Hypotheses",
    "text": "Form Hypotheses\n\nQuestion-1\n\nState the Question or Hypothesis\n(Temporarily) Drop variables using dplyr::select()\nCreate new variables if needed with dplyr::mutate()\nFilter the data set using dplyr::filter()\nReformat data if needed with tidyr::pivot_longer() or tidyr::pivot_wider()\nAnswer the Question with a Table, a Chart, a Test, using an appropriate Model for Statistical Inference\nUse title, subtitle, legend and scales appropriately in your chart\nPrefer ggformula unless you are using a chart that is not yet supported therein (eg. ggbump() or plot_likert())\n\n\n## Set graph theme\n## Idotic that we have to repeat this every chunk\n## Open issue in Quarto\n\npenguins %&gt;% \n  drop_na() %&gt;% \n  gf_point(body_mass_g ~ flipper_length_mm, \n           colour = ~ species) %&gt;% \n  gf_labs(title = \"My First Penguins Plot\",\n          subtitle = \"Using ggformula with fonts\",\n          x = \"Flipper Length mm\", y = \"Body Mass gms\",\n          caption = \"I love penguins, and R\") %&gt;% \n  gf_theme(theme_classic()) %&gt;% \n  gf_theme(theme(\n      panel.grid.minor = element_blank(),\n      ###\n      text = element_text(family = \"fira\", size = 14),\n      ###\n      plot.title = element_text(\n      family = \"roboto\",\n      face = \"bold\",\n      size = 28, hjust = 0\n    ),\n    plot.subtitle = element_text(\n      family = \"montserrat\",\n      face = \"bold\",\n      size = 18, hjust = 0),\n    \n    plot.margin = margin(2,2,2,2, unit = \"pt\"),\n    \n    axis.title = element_text(size = 20),\n    \n    plot.caption = element_text(family = \"gochi\", size = 14),\n    \n    legend.title = element_text(\n      family = \"bell\",\n      face = \"bold\",\n      size = 20\n    ),\n    legend.text = element_text(family = \"fira\",\n                               size = 12),\n    \n    legend.background = element_rect(fill = \"cornsilk\",\n                                     colour = \"black\"),\n    legend.margin = margin(\n      t = 2,\n      r = 2,\n      b = 2,\n      l = 2,\n      unit = \"pt\"\n    )\n    ))\n\n\n\n\n\n\n\n\n\n\nInference-1\n. . . .\n\n\nQuestion-n\n….\n\n\nInference-n\n…."
  },
  {
    "objectID": "posts/Workflow/index.html#iconify-carbon-chart-3d-one-most-interesting-graph",
    "href": "posts/Workflow/index.html#iconify-carbon-chart-3d-one-most-interesting-graph",
    "title": " Facing the Abyss - WorkFLow",
    "section": "{{< iconify ic outline-interests >}}{{< iconify carbon chart-3d >}} One Most Interesting Graph",
    "text": "{{&lt; iconify ic outline-interests &gt;}}{{&lt; iconify carbon chart-3d &gt;}} One Most Interesting Graph"
  },
  {
    "objectID": "posts/Workflow/index.html#conclusion",
    "href": "posts/Workflow/index.html#conclusion",
    "title": " Facing the Abyss - WorkFLow",
    "section": "Conclusion",
    "text": "Conclusion\nDescribe what the graph shows and why it so interesting. What could be done next?"
  },
  {
    "objectID": "posts/Workflow/index.html#references",
    "href": "posts/Workflow/index.html#references",
    "title": " Facing the Abyss - WorkFLow",
    "section": "References",
    "text": "References\n\nhttps://shancarter.github.io/ucb-dataviz-fall-2013/classes/facing-the-abyss/"
  },
  {
    "objectID": "posts/Workflow/index.html#one-most-interesting-graph",
    "href": "posts/Workflow/index.html#one-most-interesting-graph",
    "title": " Facing the Abyss - WorkFLow",
    "section": "One Most Interesting Graph",
    "text": "One Most Interesting Graph"
  },
  {
    "objectID": "posts/day-3(2)/index.html#banned-books-data-set-trying-it-myself",
    "href": "posts/day-3(2)/index.html#banned-books-data-set-trying-it-myself",
    "title": "Day 3",
    "section": "Banned Books data-set (Trying it myself)",
    "text": "Banned Books data-set (Trying it myself)\n\nbanned &lt;- read_csv(\"../../data/banned-author-title.csv\")\n\nRows: 1586 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): Author, Title, Type of Ban, State, District, Date of Challenge/Remo...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nbanned\n\n# A tibble: 1,586 × 7\n   Author              Title `Type of Ban` State District Date of Challenge/Re…¹\n   &lt;chr&gt;               &lt;chr&gt; &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;                 \n 1 Àbíké-Íyímídé, Far… Ace … Banned from … Flor… Indian … Nov-21                \n 2 Acevedo, Elizabeth  Clap… Banned from … Penn… Central… Sep-21                \n 3 Acevedo, Elizabeth  The … Banned from … Flor… Indian … Nov-21                \n 4 Acevedo, Elizabeth  The … Banned from … New … Marlbor… Feb-22                \n 5 Acevedo, Elizabeth  The … Banned Pendi… Texas Frederi… Mar-22                \n 6 Acevedo, Elizabeth  The … Banned Pendi… Virg… New Ken… Oct-21                \n 7 Aciman, André       Call… Banned Pendi… Virg… Spotsly… Nov-21                \n 8 Acito, Marc         How … Banned Pendi… Flor… Indian … Nov-21                \n 9 Adeyoha, Koja       47,0… Banned from … Penn… Central… Sep-21                \n10 Adichie, Chimamand… Half… Banned from … Mich… Hudsonv… Jan-22                \n# ℹ 1,576 more rows\n# ℹ abbreviated name: ¹​`Date of Challenge/Removal`\n# ℹ 1 more variable: `Origin of Challenge` &lt;chr&gt;\n\n\n\nbanned %&gt;% dplyr::glimpse()\n\nRows: 1,586\nColumns: 7\n$ Author                      &lt;chr&gt; \"Àbíké-Íyímídé, Faridah\", \"Acevedo, Elizab…\n$ Title                       &lt;chr&gt; \"Ace of Spades\", \"Clap When You Land\", \"Th…\n$ `Type of Ban`               &lt;chr&gt; \"Banned from Libraries and Classrooms\", \"B…\n$ State                       &lt;chr&gt; \"Florida\", \"Pennsylvania\", \"Florida\", \"New…\n$ District                    &lt;chr&gt; \"Indian River County School\", \"Central Yor…\n$ `Date of Challenge/Removal` &lt;chr&gt; \"Nov-21\", \"Sep-21\", \"Nov-21\", \"Feb-22\", \"M…\n$ `Origin of Challenge`       &lt;chr&gt; \"Administrator\", \"Administrator\", \"Adminis…\n\n\n\n banned %&gt;% mosaic::inspect()\n\n\ncategorical variables:  \n                       name     class levels    n missing\n1                    Author character    797 1586       0\n2                     Title character   1145 1586       0\n3               Type of Ban character      4 1586       0\n4                     State character     26 1586       0\n5                  District character     86 1586       0\n6 Date of Challenge/Removal character     12 1586       0\n7       Origin of Challenge character      2 1586       0\n                                   distribution\n1 Kobabe, Maia (1.9%) ...                      \n2 Gender Queer: A Memoir (1.9%) ...            \n3 Banned Pending Investigation (46.1%) ...     \n4 Texas (45%), Pennsylvania (28.8%) ...        \n5 Central York (27.8%) ...                     \n6 Sep-21 (28.8%), Dec-21 (28.3%) ...           \n7 Administrator (95.6%) ...                    \n\n\n\n\n\n\n\n\n\n\nVariable name\nDescription\nType of variable\n\n\n\n\nAuthor\nRepresents the name of the author of the book that has been challenged or banned\nQualitative\n\n\nTitle\nThis variable indicates the title of the book that has faced challenges or bans.\nQualitative\n\n\nType of Ban\nDescribes the context in which the book is banned\nQualitative\n\n\nState\nIndicates the U.S. state where the challenge or ban occurred.\nQualitative\n\n\nDistrict\nThis variable specifies the school district or library district involved in the challenge or ban.\nQualitative\n\n\nDate of Challenge/Removal\nThis variable records the date when the challenge was made or when the book was removed from circulation.\nQualitative\n\n\nOrigin of Challenge\nIndicates who initiated the challenge\nQualitative\n\n\n\n\nType of ban, State, District, Date of challenge and origin of challenge can be declared as factors.\n\n\nWhat could the target variable be?\nI guess it could be type of ban - understanding it could help predict if a book will be fully banned, temporarily banned, or restricted or with State/district, we could understand which states or districts are more likely to challenge books.\nWhen it comes to predictor variables, everything except title, author and district (there way too many levels) could be predictor variables.\n\nbanned_modified &lt;- banned %&gt;%\n  dplyr::mutate(\n    `Type of Ban` = as_factor(`Type of Ban`),\n    State = as_factor(State),\n    District = as_factor(District),\n    `Date of Challenge/Removal` = as_factor(`Date of Challenge/Removal`),\n    `Origin of Challenge` = as_factor(`Origin of Challenge`),\n  )\nglimpse(banned_modified)\n\nRows: 1,586\nColumns: 7\n$ Author                      &lt;chr&gt; \"Àbíké-Íyímídé, Faridah\", \"Acevedo, Elizab…\n$ Title                       &lt;chr&gt; \"Ace of Spades\", \"Clap When You Land\", \"Th…\n$ `Type of Ban`               &lt;fct&gt; Banned from Libraries and Classrooms, Bann…\n$ State                       &lt;fct&gt; Florida, Pennsylvania, Florida, New York, …\n$ District                    &lt;fct&gt; Indian River County School, Central York, …\n$ `Date of Challenge/Removal` &lt;fct&gt; Nov-21, Sep-21, Nov-21, Feb-22, Mar-22, Oc…\n$ `Origin of Challenge`       &lt;fct&gt; Administrator, Administrator, Administrato…\n\n\n\nbanned_modified %&gt;% mosaic::inspect()\n\n\ncategorical variables:  \n                       name     class levels    n missing\n1                    Author character    797 1586       0\n2                     Title character   1145 1586       0\n3               Type of Ban    factor      4 1586       0\n4                     State    factor     26 1586       0\n5                  District    factor     86 1586       0\n6 Date of Challenge/Removal    factor     12 1586       0\n7       Origin of Challenge    factor      2 1586       0\n                                   distribution\n1 Kobabe, Maia (1.9%) ...                      \n2 Gender Queer: A Memoir (1.9%) ...            \n3 Banned Pending Investigation (46.1%) ...     \n4 Texas (45%), Pennsylvania (28.8%) ...        \n5 Central York (27.8%) ...                     \n6 Sep-21 (28.8%), Dec-21 (28.3%) ...           \n7 Administrator (95.6%) ...                    \n\n\n\nbanned_modified %&gt;% skimr::skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n1586\n\n\nNumber of columns\n7\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nfactor\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nAuthor\n0\n1\n7\n29\n0\n797\n0\n\n\nTitle\n0\n1\n2\n155\n0\n1145\n0\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nType of Ban\n0\n1\nFALSE\n4\nBan: 731, Ban: 474, Ban: 197, Ban: 184\n\n\nState\n0\n1\nFALSE\n26\nTex: 713, Pen: 456, Flo: 204, Okl: 43\n\n\nDistrict\n0\n1\nFALSE\n86\nCen: 441, Nor: 435, Ind: 161, Gra: 131\n\n\nDate of Challenge/Removal\n0\n1\nFALSE\n12\nSep: 456, Dec: 449, Nov: 227, Jan: 178\n\n\nOrigin of Challenge\n0\n1\nFALSE\n2\nAdm: 1517, For: 69\n\n\n\n\n\n\n\nTARGET VARIABLE: State\n\nq1. Which state has the most amount of banned books?\n\ngf_bar(~State, data = banned_modified) %&gt;%\n  gf_labs(title = \"Counts of States\")%&gt;%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n\n\n\n\n\n\n\n\nAs expected, Texas leads the nation in the number of banned books, with Pennsylvania following in second place.\n\nSince there is data on so many states, like we did on day 4, i want to filter it to be only 10 states with the most amount of banned books.\n\n\ntop_states &lt;- banned_modified %&gt;%\n  group_by(State) %&gt;%                   # Group by state\n  summarize(n = n()) %&gt;%                # Count banned books per state\n  slice_max(n, n = 10) %&gt;%                # Select the top 5 states\n  pull(State)                           # Extract the state names\n\n\ntop_10_states_data &lt;- banned_modified %&gt;%\n  filter(State %in% top_states)\n\n\ntop_10_states_data\n\n# A tibble: 1,524 × 7\n   Author              Title `Type of Ban` State District Date of Challenge/Re…¹\n   &lt;chr&gt;               &lt;chr&gt; &lt;fct&gt;         &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt;                 \n 1 Àbíké-Íyímídé, Far… Ace … Banned from … Flor… Indian … Nov-21                \n 2 Acevedo, Elizabeth  Clap… Banned from … Penn… Central… Sep-21                \n 3 Acevedo, Elizabeth  The … Banned from … Flor… Indian … Nov-21                \n 4 Acevedo, Elizabeth  The … Banned Pendi… Texas Frederi… Mar-22                \n 5 Acevedo, Elizabeth  The … Banned Pendi… Virg… New Ken… Oct-21                \n 6 Aciman, André       Call… Banned Pendi… Virg… Spotsly… Nov-21                \n 7 Acito, Marc         How … Banned Pendi… Flor… Indian … Nov-21                \n 8 Adeyoha, Koja       47,0… Banned from … Penn… Central… Sep-21                \n 9 Agell, Charlotte    The … Banned from … Texas North E… Dec-21                \n10 Ahmadi, Arvin       How … Banned Pendi… Texas North E… Dec-21                \n# ℹ 1,514 more rows\n# ℹ abbreviated name: ¹​`Date of Challenge/Removal`\n# ℹ 1 more variable: `Origin of Challenge` &lt;fct&gt;\n\n\nTrying kskin again with this updated data-set to see if the amount of districts are small enough to be a facor\n\ntop_10_states_data %&gt;% skimr::skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n1524\n\n\nNumber of columns\n7\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nfactor\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nAuthor\n0\n1\n7\n29\n0\n789\n0\n\n\nTitle\n0\n1\n2\n155\n0\n1133\n0\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nType of Ban\n0\n1\nFALSE\n4\nBan: 701, Ban: 464, Ban: 189, Ban: 170\n\n\nState\n0\n1\nFALSE\n10\nTex: 713, Pen: 456, Flo: 204, Okl: 43\n\n\nDistrict\n0\n1\nFALSE\n57\nCen: 441, Nor: 435, Ind: 161, Gra: 131\n\n\nDate of Challenge/Removal\n0\n1\nFALSE\n12\nSep: 451, Dec: 447, Nov: 224, Jan: 161\n\n\nOrigin of Challenge\n0\n1\nFALSE\n2\nAdm: 1479, For: 45\n\n\n\n\n\n\nNope, still too much. i guess i could try it tho.\n\n\n\nq2. What is the correlation between type of ban and the state it is challenged in?\n\ntop_10_states_data %&gt;%\n  gf_bar(~State,\n    fill = ~`Type of Ban`,\n    position = \"stack\"\n  ) %&gt;%\n  gf_labs(title = \"Type of ban by state\" ,\n    subtitle = \"Stacked Bar Chart\")%&gt;%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n\n\n\n\n\n\n\n\nIt seems that almost all books banned in Pennsylvania are banned in Classrooms and in Texas, while most of them are banned from a pending investigation, there is a significant section of it banned from libraries and classrooms\n\n\nq3. Does the ban depend on the Origin of Challenge?\n\ntop_10_states_data %&gt;%\n  gf_bar(~State,\n    fill = ~`Origin of Challenge`,\n    position = \"stack\"\n  ) %&gt;%\n  gf_labs(title = \"Origin of Challenge by state\" ,\n    subtitle = \"Stacked Bar Chart\")%&gt;%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n\n\n\n\n\n\n\n\nMost bans everywhere were raised by the administration. Interestingly, all the books banned in Pennsylvania have been challenged by the administrator. In Texas, a large majority has been challenged by Administrator but there is still a portion of it challenged formally. All banned books in Missouri were challenged formally, how surprising!\n\n\nq4. Is there a correlation between the type of ban and the Origin of challenge?\n\ngf_bar(~`Origin of Challenge` | `Type of Ban`, fill = ~State, data = top_10_states_data) %&gt;%\n  gf_labs(title = \"Counts of Ban by type of ban and origin in states\")\n\n\n\n\n\n\n\n\n\ngf_bar(~`Origin of Challenge` | State, fill = ~`Type of Ban`, data = top_10_states_data) %&gt;%\n  gf_labs(title = \"Counts of Types of Ban by State and Origin\")%&gt;%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n\n\n\n\n\n\n\n\nYou would expect that only all books whose origin was formal would be the ones banned in classrooms (over protective parents exist all over the world) but surprising, From what i can see, in Texas, most books formally banned are banned from libraries (a few also banned from classrooms and libraries) and the ones banned in Missouri are mostly banned pending investigation.\n\n\nq5. In which month of which year were most bans challenged?\n\ngf_bar(~`Date of Challenge/Removal`, data = banned_modified) %&gt;%\n  gf_labs(title = \"Count of bans every month\")%&gt;%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n\n\n\n\n\n\n\n\nMost books were banned during September and December.\n\ntop_10_states_data %&gt;%\n  gf_bar(~State,\n    fill = ~`Date of Challenge/Removal`,\n    position = \"stack\"\n  ) %&gt;%\n  gf_labs(title = \"Date of Challenge/Removal by State\" ,\n    subtitle = \"Stacked bar chart\")%&gt;%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n\n\n\n\n\n\n\n\nFrom this bar, it is clear that every state has one month where most of there bans are imposed. For Texas it’s mostly in December, some in January, fewer in March, fall and November. For Pennsylvania, it’s moslty all in September. For Florida it’s mostly in November.\n\n\nq6. Is there a correlation between the type of ban and when it was challenged?\n\ngf_bar(~`Type of Ban` | `Date of Challenge/Removal`, fill = ~State, data = top_10_states_data) %&gt;%\n  gf_labs(title = \"Counts of Types of Ban by State and Date of Challenge\")%&gt;%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n\n\n\n\n\n\n\n\nTo no surprise, there does not seem to be any correlation between type of ban and the month it was challenged in.\n\n\nq7. Is there a correlation between the origin of ban and when it was challenged?\nI know it’s a long shot.\n\ngf_bar(~`Origin of Challenge` | State, fill = ~`Date of Challenge/Removal`, data = top_10_states_data) %&gt;%\n  gf_labs(title = \"Origin of challenge of State and Date of Challenge/Removal\")%&gt;%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n\n\n\n\n\n\n\n\nThere doesn’t seem to be any clear correlation between origin of ban and when it was challenged except in Tennesse where most if not all administrator origins came at Winter 2021 and all formal challenges came of September 2021.\n\n\nq8. Which author has the honor of being the most banned?\nI know this doesn’t really come under the bar graph theme we were going with in this post but i really wanted to know and when i did yry and make it a bar graph, i wasn;t getting one with all the same counts.\n\ntop_author &lt;- banned_modified %&gt;%\n  count(Author) %&gt;%\n  slice_max(n, n = 10)  \n\ntop_author\n\n# A tibble: 10 × 2\n   Author                 n\n   &lt;chr&gt;              &lt;int&gt;\n 1 Kobabe, Maia          30\n 2 Hopkins, Ellen        27\n 3 Johnson, George M.    21\n 4 Do, Anh               17\n 5 Evison, Jonathan      16\n 6 Faruqi, Saadia        16\n 7 Jules, Jacqueline     16\n 8 Morrison, Toni        16\n 9 Myracle, Lauren       16\n10 Pérez, Ashley Hope    16\n\n\nKobabe, Maia is the author with the most number of banned books, so proud of him or her!\n\n\nq9. Which District of Texas has raised the most challenges?\n\ntop_1_state &lt;- banned_modified %&gt;%\n  group_by(State) %&gt;%                   \n  summarize(n = n()) %&gt;%                \n  slice_max(n, n = 1) %&gt;%                \n  pull(State)\n\ntop_1_states_data &lt;- banned_modified %&gt;%\n  filter(State %in% top_1_state)\n\n\ngf_bar(~District, data = top_1_states_data, fill = \"lightblue\") %&gt;%\n  gf_labs(title = \"Counts of Districts in Texas\")%&gt;%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n\n\n\n\n\n\n\n\nThe North East District of Texas has the most number of challenges/ bans\n\n\n\nThe End of my A1."
  }
]