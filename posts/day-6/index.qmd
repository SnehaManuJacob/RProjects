---
title: "Day 6 and 7"
author: "Sneha Manu Jacob"
date: "2024-10-17"
categories: [ Statistics, Central Limit Theorem, randamoisation ]
---

```{r}
library(tidyverse) # Data Processing in R
library(mosaic) # Our workhorse for stats, sampling
library(skimr) # Good to Examine data
library(ggformula) # Formula interface for graphs

# load the NHANES data library
library(NHANES)
library(infer)
library(broom) # Clean test results in tibble form
library(resampledata) # Datasets from Chihara and Hesterberg's book
library(openintro) # More datasets
```

```{r}
data("NHANES")
glimpse(NHANES)
```

## Introduction:

Sample of data is taken and theoretically all means are normally distributed. Can we take that distributed and pretend that out data is also normally distributed.

### Populations and sampling.

The population is the whole of your target audience but considering that it's kind of impossible to get observations for all of them, we take the next best thing- a sample. The sample population are representative of the entire population. Using sample, we can calculate and figure out a sample statistic using which we can derive observations on the population

```{r}
NHANES_adult <-
  NHANES %>%
  distinct(ID, .keep_all = TRUE) %>%
  filter(Age >= 18) %>%
  select(Height) %>%
  drop_na(Height)
NHANES_adult
```

#### Population mean and standard deviation

```{r}
pop_mean <- mosaic::mean(~Height, data = NHANES_adult)

pop_sd <- mosaic::sd(~Height, data = NHANES_adult)

pop_mean

pop_sd 
```

#### Collecting a random sample.

```{r}
sample_50 <- mosaic::sample(NHANES_adult, size = 50) %>%
  select(Height)
sample_50
sample_mean_50 <- mean(~Height, data = sample_50)
sample_mean_50
```

#### Comparing the Sample Mean and Popolation mean

```{r}
sample_50 %>%
  gf_histogram(~Height, bins = 10) %>%
  gf_vline(
    xintercept = ~sample_mean_50,
    color = "purple"
  ) %>%
  gf_vline(
    xintercept = ~pop_mean,
    colour = "black"
  ) %>%
  gf_label(7 ~ (pop_mean + 8),
    label = "Population Mean",
    color = "black"
  ) %>%
  gf_label(7 ~ (sample_mean_50 - 8),
    label = "Sample Mean", color = "purple"
  ) %>%
  gf_labs(
    title = "Distribution and Mean of a Single Sample",
    subtitle = "Sample Size = 50"
  )
```

#### Collecting the sample of the same size, randomely mutiple times

```{r}
sample_50_500 <- do(500) * {
  sample(NHANES_adult, size = 50) %>%
    select(Height) %>% # drop sampling related column "orig.id"
    summarise(
      sample_mean = mean(Height),
      sample_sd = sd(Height),
      sample_min = min(Height),
      sample_max = max(Height)
    )
}
sample_50_500
dim(sample_50_500)
```

getting the estimate of all mean values obtained from individual samples to get a more accurate value of sample mean.

```{r}
sample_50_500 %>%
  gf_point(.index ~ sample_mean,
    color = "purple",
    title = "Sample Means are close to the Population Mean",
    subtitle = "Sample Means are Random!",
    caption = "Grey lines represent our 500 samples"
  ) %>%
  gf_segment(
    .index + .index ~ sample_min + sample_max,
    color = "grey",
    linewidth = 0.3,
    alpha = 0.3,
    ylab = "Sample Index (1-500)",
    xlab = "Sample Means"
  ) %>%
  gf_vline(
    xintercept = ~pop_mean,
    color = "black"
  ) %>%
  gf_label(-25 ~ pop_mean,
    label = "Population Mean",
    color = "black"
  )
```

Any mean can be more or less, therefore it is fair. i can trust the mean. A sample mean is a good point to estimate the data.

```{r}
sample_50_500 %>%
  gf_point(.index ~ sample_sd,
    color = "purple",
    title = "Sample SDs are close to the Population Sd",
    subtitle = "Sample SDs are Random!",
  ) %>%
  gf_vline(
    xintercept = ~pop_sd,
    color = "black"
  ) %>%
  gf_label(-25 ~ pop_sd,
    label = "Population SD",
    color = "black"
  ) %>%
  gf_refine(lims(x = c(4, 16)))
```

```{r}
sample_50_500 %>%
  gf_dhistogram(~sample_mean, bins = 30, xlab = "Height") %>%
  gf_vline(
    xintercept = pop_mean,
    color = "blue"
  ) %>%
  gf_label(0.01 ~ pop_mean,
    label = "Population Mean",
    color = "blue"
  ) %>%
  gf_labs(
    title = "Sampling Mean Distribution",
    subtitle = "500 means"
  )

```

```{r}
# How does this **distribution of sample-means** compare with the
# overall distribution of the population?
#
sample_50_500 %>%
  gf_dhistogram(~sample_mean, bins = 30, xlab = "Height") %>%
  gf_vline(
    xintercept = pop_mean,
    color = "blue"
  ) %>%
  gf_label(0.01 ~ pop_mean,
    label = "Population Mean",
    color = "blue"
  ) %>%
  ## Add the population histogram
  gf_histogram(~Height,
    data = NHANES_adult,
    alpha = 0.2, fill = "blue",
    bins = 30
  ) %>%
  gf_label(0.025 ~ (pop_mean + 20),
    label = "Population Distribution", color = "blue"
  ) %>%
  gf_labs(title = "Sampling Mean Distribution", subtitle = "Original Population overlay")
```

## **Deriving the Central Limit Theorem (CLT)**

As sample lenght increases, the density graph becomes narrower.

let's test this out:

```{r}
samples_08_1000 <- do(1000) * mean(resample(NHANES_adult$Height, size = 08))

samples_16_1000 <- do(1000) * mean(resample(NHANES_adult$Height, size = 16))

samples_32_1000 <- do(1000) * mean(resample(NHANES_adult$Height, size = 32))

samples_64_1000 <- do(1000) * mean(resample(NHANES_adult$Height, size = 64))

# samples_128_1000 <- do(1000) * mean(resample(NHANES_adult$Height, size = 128))
```

I will receive 1000 values for each sample size

The plotting of the 1000 values each seperately

```{r}
# Let us overlay their individual histograms to compare them:
p5 <- gf_dhistogram(~mean,
  data = samples_08_1000,
  color = "grey",
  fill = "dodgerblue", title = "N = 8"
) %>%
  gf_fitdistr(linewidth = 1) %>%
  gf_vline(
    xintercept = pop_mean, inherit = FALSE,
    color = "blue"
  ) %>%
  gf_label(-0.025 ~ pop_mean,
    label = "Population Mean",
    color = "blue"
  ) %>%
  gf_theme(scale_y_continuous(expand = expansion(mult = c(0.08, 0.02))))
##
p6 <- gf_dhistogram(~mean,
  data = samples_16_1000,
  color = "grey",
  fill = "sienna", title = "N = 16"
) %>%
  gf_fitdistr(linewidth = 1) %>%
  gf_vline(
    xintercept = pop_mean,
    color = "blue"
  ) %>%
  gf_label(-.025 ~ pop_mean,
    label = "Population Mean",
    color = "blue"
  ) %>%
  gf_theme(scale_y_continuous(expand = expansion(mult = c(0.08, 0.02))))
##
p7 <- gf_dhistogram(~mean,
  data = samples_32_1000,
  na.rm = TRUE,
  color = "grey",
  fill = "palegreen", title = "N = 32"
) %>%
  gf_fitdistr(linewidth = 1) %>%
  gf_vline(
    xintercept = pop_mean,
    color = "blue"
  ) %>%
  gf_label(-.025 ~ pop_mean,
    label = "Population Mean", color = "blue"
  ) %>%
  gf_theme(scale_y_continuous(expand = expansion(mult = c(0.08, 0.02))))

p8 <- gf_dhistogram(~mean,
  data = samples_64_1000,
  na.rm = TRUE,
  color = "grey",
  fill = "violetred", title = "N = 64"
) %>%
  gf_fitdistr(linewidth = 1) %>%
  gf_vline(
    xintercept = pop_mean,
    color = "blue"
  ) %>%
  gf_label(-.025 ~ pop_mean,
    label = "Population Mean", color = "blue"
  ) %>%
  gf_theme(scale_y_continuous(expand = expansion(mult = c(0.08, 0.02))))

# patchwork::wrap_plots(p5,p6,p7,p8)
p5
p6
p7
p8
```

The bell curve distribution become more and more narrow. The range in the x axis, reduces as the sample size reduces. Despite this, the mean values are very similar values. This bell curve give you the estimate of standard error.

Therefore,

-   the sample-means are normally distributed around the *population mean*. So any mean of a **single sample** is a good, **unbiased estimate** for the `pop_mean`

-   the **sample-mean distributions** narrow with sample length, i.e their `sd` decreases with increasing sample size.

-   This is regardless of the distribution of the *population* itself. It does not matter if it is skewed or not

The standard deviation of all sample means of a size is called the **standard error**

the *Standard Error* can be computed from **a single sample** as:

```{r}
pop_sd <- sd(~Height, data = NHANES_adult)
pop_sd
sd(~Height, data = sample_08) / sqrt(8)
sd(~Height, data = sample_16) / sqrt(16)
sd(~Height, data = sample_32) / sqrt(32)
sd(~Height, data = sample_64) / sqrt(64)
```

Since Standard Error decreases with sample size, we need to make our sample of adequate size. Never make n less than 30.

Standard error = sd(of the variable you are taking)/squareroot of lengh of sample

This is 95% accurate.

### **Confidence intervals**

The sample mean is very close to the population mean. But this sample mean changes as the sample changes.

If the confidence interval is lesser, the uncertainty is lesser.Assumnibg that the population is also a normal distribution. Population mean = (sample mean +\_ 2 \*standard error(of a sample with a large size)) For every sample taken, the mean calue will stradle the population mean.

## Randomization:

We don't belive anything is happening and we want data to prove us wrong.

**Let’s figure out how hard it is to get 9 out of 10 by guessing**. If it’s not so hard to do, then perhaps that’s just what happened ( that she was guessing ), so we won’t be too impressed with the lady’s tea tasting ability. On the other hand, if it is really unusual to get 9 out of 10 correct by guessing, then we will have some evidence that she must be able to tell something ( and has an unusual Skill).

Seeing what the chances are that the data concluded the way it did by chance? More typically, we will use randomization to create new simulated data sets ( “Parallel Worlds”) that are like our original data in some ways, but make the null hypothesis true. For each simulated data set, we calculate our test statistic, just as we did for the original sample. Together, this collection of test statistics computed from the simulated samples constitute our randomization distribution.

## Inference for a single mean

### Toy Data

Statistical Inference is almost an Attitude!

There are 2 conclutions you can come to:

a.  there is really nothing happening with our research question, and that anything we see in the data is the outcome of random chance.

b.  the value/statistic indicated by the data is off the mark and ought to be something else.

```{r}
set.seed(40)  # for replication
# Data as individual vectors ( for t.tests etc)
y <- rnorm(50, mean = 2, sd = 2)

# And as tibble too
mydata <- tibble(y = y)
mydata
```

The code I provided is generating random data from a normal distribution and storing it both as a numeric vector and as a tibble (a type of data frame in R). The argument `40` is the seed value. If someone else runs this code with the same seed, they will generate the exact same random values for `y`. The random numbers will have a mean (average) of 2, the standard deviation of the random numbers will be 2.

```{r}
mydata %>%
    gf_density(~y) %>%
    gf_fitdistr(dist = "dnorm") %>%
    gf_labs(title = "Densities of Original Data Variables", subtitle = "Compared with Normal Density")
```

Observations: It's not a normal distribition. As specifies, the values center around 2.

### Assumptions

The assumption is that mean i 0.But also alternatively create a hypothesis that it is not 0.

the fact that the districbution is not normal will affect the test we can use to make inferences about the population mean. Regardless, let's do the same.

#### T-test:

one-sample t-test on the variable y to test whether the mean of y differs significantly from a specified population mean in this case out first assumption: 0.

```{r}
# t-test
t1 <- mosaic::t_test(
          y, # Name of variable
          mu = 0, # belief of population mean
          alternative = "two.sided") %>% # Check both sides
  
  broom::tidy() # Make results presentable, and plottable!!
t1
```

It tests both sides of the distribution, meaning that it checks if the mean of y is significantly greater than or less than 0. It does not assume a specific direction for the difference.

Observations:

1.  The p-value, indicates the significance of the result. It's extremely small, indicating that the difference between the sample mean and 0 is statistically significant. Essentially, this means there's a very low probability that the sample mean of 2.04 is due to random chance if the true mean were 0.
2.  The confidence interval \[1.4399, 2.6515\] provides a range for where the true mean likely lies.Since 0 is not within this range, the test confirms that the population mean is very likely not 0.

#### Intuitive:

the background of t-test:

```{r}
mean_belief_pop <- 0  # Assert our belief
# Sample Mean
mean_y <- mean(y)
mean_y
```

pop mean= sample mean

```{r}
mean_belief_pop <- 0  # Assert our belief
# Sample Mean
sd_y <- sd(y)
sd_y
```

sample sd = pop sd

```{r}
std_error <- sd(y)/sqrt(length(y))
std_error
```

```{r}
## Confidence Interval of Observed Mean
conf_int <- tibble(ci_low = mean_y - 1.96 * std_error, ci_high = mean_y + 1.96 *
    std_error)
conf_int
```

95% of all sample means lie within this confiedence interval

```{r}
## Difference between actual and believed mean
mean_diff <- mean_y - mean_belief_pop
mean_diff
```

```{r}
t <- mean_diff/std_error
t
```

At this distance of 6.78, we would have negligible probability of this data occurring by chance! Anything more than a distance of 2 is highly unlikely, 2 itself only have a 5% probability.

#### Wilcoxon’s Signed-Rank Test

If our assumption about normality has been invalidated, the data is used in rank-transformed sense/order. In some cases the signed-rank of the data values is used instead of the data itself. The signed ranks are then tested to see if there are more of one polarity than the other, roughly speaking, and how probable this could be.

1.  Take the absolute value of each observation in a sample
2.  Place the ranks in order of (absolute magnitude). The smallest number has rank = 1 and so on.
3.  Give each of the ranks the sign of the original observation ( + or -)

```{r}
signed_rank <- function(x) {
    sign(x) * rank(abs(x))
}
```

```{r}
# Standard Wilcoxon Signed_Rank Test
t2 <- wilcox.test(y, # variable name
                  mu = 0, # belief
                  alternative = "two.sided",
                  conf.int = TRUE,
                  conf.level = 0.95) %>% 
  broom::tidy()
t2
```

### Using Permutation and Bootstrap

```{r}
# Calculate exact mean
obs_mean <- mean( ~ y, data = mydata)
belief1 <- 0 # What we think the mean is
obs_diff_mosaic <- obs_mean - belief1
obs_diff_mosaic
```

Start with the belief that a mean is nothing special.

```{r}
## Steps in Permutation Test
## Repeatedly Shuffle polarities of data observations
## Take means
## Compare all means with the real-world observed one
null_dist_mosaic <- 
mosaic::do(9999) * mean( ~ abs(y) * 
          sample(c(-1, 1), # +/- 1s multiply y
            length(y),     # How many +/- 1s?
            replace = T),  # select with replacement
        data = mydata)
##
range(null_dist_mosaic$mean)
```

Permutations of signs. 50000 new fictitious samples are created and plot it.5000 arrays of -1 and 1 are created and multiplied with my sample. If the mean of the histogram falls within the estimate. It's nothing special.

```{r}
## Plot this NULL distribution
gf_histogram(
  ~ mean,
  data = null_dist_mosaic,
  fill = ~ (mean >= obs_diff_mosaic),
  bins = 50, title = "Distribution of Permutation Means under Null Hypothesis",
  subtitle = "Why is the mean of the means zero??") %>%
  gf_labs(x = "Calculated Random Means",
          y = "How Often do these occur?") %>% 
  gf_vline(xintercept = obs_diff_mosaic, colour = "red")
```

Here we twist data to try and mimic nature. If i am not able to do this, it proves that i didn't get what i got, by chance. Something is happening!

## Exam Data:

### Inspecting data:

```{r}
exam_grades %>%
    gf_density(~course_grade) %>%
    gf_fitdistr(dist = "dnorm") %>%
    gf_labs(title = "Density of Course Grade", subtitle = "Compared with Normal Density")
```

data looks normally distributed.

#### Testing assumptions:

The Shapiro-Wilkes Test tests whether a data variable is normally distributed or not. Without digging into the maths of it, let us say it makes the assumption that the variable is so distributed and then computes the probability of how likely this is. So a high p-value is a good thing here.

```{r}
stats::shapiro.test(x = exam_grades$course_grade) %>%
    broom::tidy()
```

It is normally distributed
